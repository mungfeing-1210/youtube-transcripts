---
layout: default
title: "The Godmother of AI on jobs, robots & why world models are next | Dr. Fei-Fei Li"
channel: "Lenny's Podcast"
date: 2025-11-16
---

# The Godmother of AI on jobs, robots & why world models are next | Dr. Fei-Fei Li

**频道**: Lenny's Podcast
**发布日期**: 2025-11-16
**视频链接**: https://www.youtube.com/watch?v=Ctjiatnd6Xk

---

## Key Takeaways

## 一句话总结
Dr. Fei-Fei Li，AI 领域的“教母”，分享了她对 AI 发展史、当前局势以及未来方向的深刻洞见，强调了数据、人类中心主义以及“世界模型”（World Models）作为 AI 下一个重要突破点的关键作用。

## 内容概览
本视频深入探讨了 AI 的发展历程，从 AI Winter 到现代深度学习的兴起，并聚焦于 Dr. Fei-Fei Li 在 ImageNet 项目中的关键贡献。她阐述了 AI 对人类社会的双刃剑效应，强调了负责任的个体和集体在 AI 发展中的重要性。视频还详细介绍了“世界模型”的概念、其重要性以及 World Labs 公司发布的开创性产品 Marble，并探讨了其在机器人、游戏、虚拟制作和科学发现等领域的巨大潜力。

## 核心要点

### 1. ImageNet：AI 走出“寒冬”的关键催化剂
**背景/问题**: AI 领域曾经历“AI Winter”，研究停滞，公众信心不足。AI 模型的发展受限于缺乏大规模、高质量的标注数据。
**核心观点**: Dr. Fei-Fei Li 认识到人类学习是大数据驱动的，因此发起了 ImageNet 项目，收集并标注了 1500 万张图像，涵盖 22,000 个概念。ImageNet 的出现为深度学习模型的训练提供了关键的“燃料”。
**实践启示**: 大规模、高质量的数据集是推动 AI 模型突破的关键。ImageNet 的成功证明了数据驱动方法的力量，为后续的深度学习革命奠定了基础。

### 2. AI 的本质：人类的延伸，而非替代
**背景/问题**: 对 AI 将取代人类工作、甚至威胁人类生存的担忧普遍存在。
**核心观点**: Dr. Fei-Fei Li 强调 AI“nothing artificial about AI. It's inspired by people. It's created by people. And most importantly, it impacts people.” AI 的发展和应用最终取决于人类的选择和责任。她认为技术总体上是人类的净积极因素，但也是一把双刃剑，需要负责任地使用。
**实践启示**: AI 的发展方向和最终影响由人类社会共同塑造。个体和集体需要对 AI 的发展和应用承担责任，确保其服务于人类福祉。

### 3. “世界模型”（World Models）：AI 理解和交互世界的下一站
**背景/问题**: 当前的 AI 模型（如 Large Language Models）在理解三维空间、物理交互和情境感知方面存在局限，这阻碍了 AI 在机器人、具身智能（embodied AI）等领域的进一步发展。
**核心观点**: World Models 旨在赋予 AI 类似于人类的空间智能和世界理解能力，使其能够构建、理解和与虚拟或真实世界进行交互。这比仅仅处理文本或视频更进一步，能够进行推理、规划和行动。
**实践启示**: World Models 是通往更通用、更智能 AI 的重要路径，尤其对于机器人和需要与物理世界交互的应用至关重要。

### 4. Marble：首个生成式 3D 世界模型产品
**背景/问题**: 缺乏易于使用的工具来创建和探索 3D 世界，限制了其在游戏、虚拟制作、机器人模拟等领域的应用。
**核心观点**: World Labs 推出的 Marble 是世界上第一个生成式 3D 世界模型产品，用户可以通过文本和图像提示（prompt to worlds）来创建可导航、可交互的 3D 世界。它将空间智能与生成式 AI 相结合。
**实践启示**: Marble 降低了 3D 世界创建的门槛，为电影虚拟制作、游戏开发、机器人仿真、心理学研究等领域提供了强大的新工具，极大地加速了内容创作和模拟过程。

### 5. 视觉智能与空间智能的重要性
**背景/问题**: 早期 AI 研究侧重于逻辑和语言，但人类智能很大程度上依赖于视觉和空间感知。
**核心观点**: Dr. Fei-Fei Li 从视觉智能切入 AI 研究，并进一步强调了空间智能（spatial intelligence）的重要性。她认为，人类对世界的理解和互动，从识别物体到进行复杂的物理操作，都离不开空间智能。
**实践启示**: 将视觉和空间智能作为 AI 研究的核心组成部分，能够更好地模拟人类的感知和认知能力，推动 AI 在更广泛的场景中应用。

### 6. “苦涩教训”（Bitter Lesson）在机器人领域的局限性
**背景/问题**: Richard Sutton 提出的“苦涩教训”认为，在 AI 领域，更简单的模型加上海量数据往往能取得最终胜利。然而，机器人领域的数据获取和模型训练面临独特挑战。
**核心观点**: 机器人领域的“苦涩教训”可能不完全适用。机器人训练数据（如行动和 3D 世界交互）与语言模型数据（文本）存在根本差异，数据获取难度更大。此外，机器人是物理系统，其发展路径更像自动驾驶，需要大脑、身体和应用场景的协同，是一个长期且复杂的过程。
**实践启示**: 机器人领域的突破需要超越简单的“数据+模型”范式，需要更创新的数据获取方式（如合成数据、遥操作数据）和对物理世界交互的深入理解。

### 7. AI 的历史：集体的智慧，而非个人英雄主义
**背景/问题**: Silicon Valley 的文化倾向于将成就归功于个人，而忽略了 AI 领域长达 70 年的集体努力。
**核心观点**: Dr. Fei-Fei Li 强调 AI 是一个跨越数代研究人员集体努力的领域，她本人也受益于许多前人的启发。她反对将 AI 的成就简单归结于少数人。
**实践启示**: 认识到 AI 发展的集体性，尊重和学习前人的贡献，有助于更全面地理解 AI 的进步，并鼓励更广泛的合作。

### 8. AGI 的定义与现实
**背景/问题**: AGI（Artificial General Intelligence）是一个模糊且常被讨论的概念，其定义和实现路径并不清晰。
**核心观点**: Dr. Fei-Fei Li 认为 AGI 更像是一个营销术语，而非严格的科学定义。她更关注 AI 的核心问题——“机器能否像人类一样思考和行动”，并认为我们在实现这一目标的道路上已经取得了显著进展，但离完全实现还有很长的路要走，需要持续的创新。
**实践启示**: 聚焦于 AI 的具体能力提升和实际应用，而非过度纠结于 AGI 的定义，更有助于推动 AI 的健康发展。

### 9. 人类大脑的奇迹与 AI 的敬畏
**背景/问题**: 面对 AI 的快速发展，容易忽视人类自身大脑的复杂性和高效性。
**核心观点**: Dr. Fei-Fei Li 表示，越深入研究 AI，越会敬畏人类大脑的强大，其仅以 20 瓦的功耗就能完成如此复杂的任务。
**实践启示**: AI 的研究不仅是创造智能，也是对人类自身智能的更深层次理解。AI 的发展应以人类智能为标杆，并从中汲取灵感。

## 关键概念与资源
**核心概念**: AI Winter, Machine Learning, Neural Networks, ImageNet, Object Recognition, Deep Learning, Big Data, GPUs, Human-Centered AI, Artificial General Intelligence (AGI), World Models, Spatial Intelligence, Embodied AI, Generative Models, Foundation Models, Prompt to Worlds, Bitter Lesson, Reinforcement Learning, Virtual Production, Robotic Simulation.
**工具/技术**: ImageNet, Deep Learning Models (e.g., AlexNet), Neural Networks, GPUs (Nvidia), Large Language Models (LLMs), Marble (World Labs product), Generative 3D Models.
**推荐资源**:
*   ImageNet dataset and challenges
*   World Labs (marble.worldlabs.ai)
*   Dr. Fei-Fei Li's book (mentioned in passing as a source of her inspirations)
*   Richard Sutton's "The Bitter Lesson" paper
*   TED Talk on Spatial Intelligence by Dr. Fei-Fei Li (mentioned)
*   Stanford Human-Centered AI Institute (HAI)

## 目标受众
**最适合**: AI 研究者、开发者、产品经理、对 AI 的未来发展趋势、技术突破和伦理问题感兴趣的科技从业者、学生以及对人工智能如何改变世界感到好奇的普通大众。
**价值场景**: 想要了解 AI 发展史和关键里程碑、探索 AI 下一个重大突破方向（World Models）、学习如何负责任地发展和应用 AI、以及对生成式 3D 内容创作感兴趣的场景。

## 延伸思考
1.  在“苦涩教训”的背景下，如何平衡数据驱动和模型创新在机器人领域的研发投入？除了 World Models，还有哪些可能突破机器人发展瓶颈的路径？
2.  “世界模型”的广泛应用是否会加剧数字鸿沟？如何确保这项技术能够普惠大众，而不是仅仅服务于少数有资源和技术能力的群体？
3.  Dr. Fei-Fei Li 强调 AI 的“人类中心”理念，在当前 AI 快速商业化和模型能力飞速提升的背景下，如何确保 AI 的发展始终服务于人类的长期福祉，避免潜在的伦理风险和社会冲击？

---

## 中文文稿

好的，这是根据您提供的英文视频字幕转录并整理的中文文稿：

**### AI 发展史与现状**

很多人称您为“AI 教母”。您所做的工作，可以说是点燃了我们走出“AI 寒冬”的火花，那大约在 2015 年到 2016 年之间。当时，一些科技公司甚至回避使用“AI”这个词，因为他们不确定 AI 是否是一个负面词汇。直到 2017 年左右，才开始有公司公开宣称自己是 AI 公司。

**### AI 的本质与影响**

您曾对国会表示：“AI 本身并没有什么‘人造’的成分。它是受人启发，由人创造，最重要的是，它影响着人。”

我认为，AI 对工作和人们的生活肯定会产生影响。事实上，我相信无论 AI 当前或将来会做什么，都取决于我们——取决于人类自己。我坚信技术对人类整体而言是积极的。但我也认为，任何技术都像一把双刃剑。如果社会和我们个人没有做正确的事情，我们也会把事情搞砸。

**### 视觉智能的突破**

您曾有过一个突破性的洞见：我们可以训练机器像人类一样思考，但它们缺少的是人类孩童时期就拥有的数据。

我选择通过视觉智能（visual intelligence）的视角来研究人工智能，因为人类是高度视觉化的动物。我们需要用尽可能多的图像信息来训练机器识别物体。然而，学习单个物体非常非常困难，因为一个物体在图像中可能呈现出无限的可能性。为了让计算机理解成千上万个物体概念，你真的需要向它展示数百万个示例。

**### 嘉宾介绍**

今天我的嘉宾是 Fei-Fei Li 博士，她被誉为“AI 教母”。Fei-Fei 在当前我们所经历的 AI 革命中，许多重大的突破都与她息息相关。她牵头创建了 ImageNet，这项工作让她意识到 AI 需要海量的、经过清晰标注的数据才能变得更智能。这个数据集成为了催化剂，促成了当前构建和扩展 AI 模型的方法。

她曾担任 Google Cloud 的首席 AI 科学家，在那里诞生了许多早期重要的技术突破。她也曾是斯坦福人工智能实验室（Stanford's AI lab）的主任，许多顶尖的 AI 人才都出自那里。她还是斯坦福以人为本人工智能研究所（Stanford's human-centered AI institute）的联合创始人，该研究所对 AI 的发展方向起着至关重要的作用。

此外，她还曾担任 Twitter 的董事会成员，并被《时代》杂志评为“AI 领域最具影响力的 100 人”之一。她也是联合国顾问委员会的成员。我还可以继续列举下去。

**### 对话内容预告**

在我们的对话中，Fei-Fei 分享了 AI 发展至今的简要历史，包括一个令人震惊的提醒：在 9 到 10 年前，自称“AI 公司”几乎是品牌自杀，因为没人相信 AI 真的能奏效。而如今，情况完全不同了，每家公司都变成了 AI 公司。

我们还聊了她对 AI 未来如何影响人类的看法，当前技术能走多远，她为何对构建“世界模型”（world model）如此热情，以及“世界模型”究竟是什么。最令人兴奋的是，她将介绍世界上第一个大型世界模型——Marble 的发布，该模型恰好在我们播客发布之际推出。任何人都可以访问 marble.worldlabs.ai 去体验它，简直太棒了！

Fei-Fei 博士非常出色，但她对世界产生的巨大影响却远未得到充分的关注。因此，我非常激动能邀请到她，并与更多人分享她的智慧。非常感谢 Ben Horowitz 和 Condoleezza Rice 提出本次对话的建议。如果您喜欢这个播客，请记得在您最喜欢的播客应用或 YouTube 上订阅和关注。

现在，在简短的广告之后，我将为您带来 Dr. Fei-Fei Li 的访谈。

**### 赞助商广告**

**Figma**

本期节目由 Figma 赞助。Figma 的 Figma Make 功能。我还在 Airbnb 担任产品经理时，就记得 Figma 的出现极大地改善了我们团队的协作方式。突然间，我可以让整个团队参与到设计过程中，快速对设计理念给出反馈，这让整个产品开发过程变得更加有趣。

但 Figma 似乎总觉得不是为我这种“构建者”设计的。它很适合提供反馈和设计，但作为开发者，我更想动手创造。这就是为什么 Figma 推出了 Figma Make。只需几个提示，你就可以将任何想法或设计转化为功能齐全的原型或应用程序，任何人都可以对其进行迭代并向客户验证。

Figma Make 是一种不同类型的低代码（low-code）工具。因为它完全集成在 Figma 中，你可以利用团队现有的设计构建模块，轻松创建外观精美、感觉真实且与团队构建方式相连的输出。别再花大量时间向别人描述你的产品愿景了，直接向他们展示吧！使用 Figma Make 快速创建可交互的原型和应用程序。请访问 figma.com/lenny 了解更多。

**JustWorks**

您知道吗？我有一个专门的团队来协助我制作播客和撰写新闻通讯。我希望团队中的每个人都能快乐地工作，并在各自的岗位上茁壮成长。JustWorks 深知，你的员工不仅仅是你的员工，他们更是你的人。我的团队分布在科罗拉多、澳大利亚、尼泊尔、西非和旧金山。

如果让我独自处理国际招聘、按时向他们支付工资（并使用当地货币），以及全天候解答他们的人力资源问题，我的生活将变得异常复杂。但有了 JustWorks，这一切都变得无比简单。无论你是设置自动工资发放、提供优质福利，还是进行国际招聘，JustWorks 都提供简单的软件和全天候的人工支持，由小企业专家为你和你的员工提供服务。他们会妥善处理你的人力资源事务，让你能够善待你的员工。JustWorks，就是为了你的人。

[音乐]

**### 对话开始**

Fei-Fei，非常感谢您来到这里，欢迎来到播客。

**嘉宾**: 很高兴来到这里，Lenny。

**主持人**: 我更激动能邀请到您。能和您聊聊真是太棒了。

好的，这是根据您提供的英文视频字幕转录并整理的高质量中文文稿：

**### AI 的历史与未来**

**主持人**：您好！我有很多话题想和您聊。您长期以来一直处于我们现在看到的 AI 爆炸式发展的中心。我们将探讨很多很多人可能都不知道的关于 AI 发展初期的历史。但首先，我想引用一段关于您的话，以便大家对您有一个初步的了解。在介绍中，我会分享您所有其他了不起的成就，但我认为从这里开始设置背景会很合适。费博士是极少数科学家中的一员，或许人数少到可以围坐在一张餐桌旁，他们对 AI 近期取得的卓越进展负有责任。很多人称您为“AI 教母”。而且，与许多 AI 领域的领导者不同，您是一位 AI 乐观主义者。您不认为 AI 会取代我们，不认为它会夺走我们所有的工作，也不认为它会毁灭我们。所以，我想从这里开始，听听您对 AI 将如何影响人类的看法。

**嘉宾（Dr. Fei-Fei Li）**：好的，Lenny，我需要非常明确地说，我不是一个乌托邦主义者。我并不是认为 AI 对工作或人类完全没有影响。事实上，我是一个人本主义者。我相信，无论 AI 现在或将来做什么，都取决于我们，取决于人们。

我确实相信技术对人类来说是净收益。纵观人类文明的长河，我认为我们本质上是一个创新的物种。如果您看看从几千年前有文字记载的历史到现在，人类一直在不断地革新自己和我们的工具，通过这些，我们让生活变得更好，让工作变得更好，我们建立了文明，我相信 AI 也是其中的一部分。这就是我乐观的来源。

但我认为，每项技术都像一把双刃剑。如果我们作为一个物种、一个社会、一个社区、一个个人没有做正确的事情，我们同样可能搞砸这一切。

**主持人**：我记得您在向国会发表演讲时说过一句话：“AI 没有什么是‘人造’的。它是受人启发，由人创造，最重要的是，它影响着人。” 这句话真是太棒了，我没有问题，只是想再次强调一下。

**嘉宾（Dr. Fei-Fei Li）**：是的，我对此深有感触。我大约在二十五年前开始从事 AI 研究，过去二十年我一直在指导学生。几乎每一个从我实验室毕业的学生，我都会提醒他们，你们的领域叫做“人工智能”，但它没有什么是人造的。

**### AI 的发展路径与责任**

**主持人**：回到您刚才提到的，AI 的发展方向在很大程度上取决于我们。您认为我们需要做对哪些事情？我们该如何引导它走上正确的道路？我知道这是一个非常难以回答的问题，但您有什么建议？您认为我们应该怎么做？

**嘉宾（Dr. Fei-Fei Li）**：我们有多少时间来讨论这个问题？

**主持人**：我们该如何让 AI 与我们保持一致？对了，我们来解决这个问题。

**嘉宾（Dr. Fei-Fei Li）**：另外，我认为人们无论做什么都应该负起责任。这是我们教导孩子的，也是我们作为成年人需要做的。无论您参与 AI 开发、部署还是应用的哪个环节——而且很可能我们中的许多人，尤其是技术人员，会同时参与多个环节——我们都应该像负责任的个体一样行事，并且非常、非常关心这件事。

我认为今天每个人都应该关心 AI，因为它将影响您的个人生活，影响您的社区，影响社会和子孙后代。作为负责任的人去关心它，是第一步，也是最重要的一步。

**### ImageNet 的诞生与 AI 的“冬天”**

**主持人**：好的，让我稍微后退一步，回到 AI 的起点。大多数人开始听到和关心 AI，是它现在被称为“AI”的时候。就像我不知道几年前 ChatGPT 出来的时候，大概是三年前吧？

**嘉宾（Dr. Fei-Fei Li）**：三年前，差不多还有一个多月。

**主持人**：哇，好的。那是 ChatGPT 问世的时候。您心里想的里程碑就是这个吗？太棒了，我当时也是这么看的。但很少有人知道，有很长很长的历史，人们一直在研究它，当时叫做机器学习（Machine Learning），还有其他一些术语。现在一切都叫 AI 了。

曾经有一段很长的时期，很多人都在默默地工作。然后出现了所谓的“AI 寒冬”（AI Winter），人们几乎都放弃了，觉得这个想法行不通了。而您所做的工作，实际上是带领我们走出 AI 寒冬的火花，直接促成了我们现在这个 AI 无处不在的世界，正如您刚才所说，它将影响我们所做的一切。

所以，我想听您讲讲，在 ImageNet 出现之前，世界是什么样的？您创建 ImageNet 的工作为什么如此重要？以及之后发生了什么？

**嘉宾（Dr. Fei-Fei Li）**：对我来说，很难想象 AI 对大家来说是如此新鲜的事物。我整个职业生涯都在 AI 领域，我很高兴看到一个我十几岁时就开始萌生的个人好奇心，如今已成为我们文明的变革力量。这确实是一项文明级别的技术。

这段旅程大约有 30 年，20 多年。看到它取得这样的成就，我感到非常满足。那么，一切从何开始呢？我甚至不是第一代 AI 研究者。第一代可以追溯到 20 世纪 50 年代和 60 年代。您知道，艾伦·图灵（Alan Turing）在 40 年代就超越了时代，他提出了一个大胆的问题：机器能否思考？当然，他有一个特定的方法来测试这种“思考机器”的概念，那就是对话式聊天机器人。按照他的标准，我们现在确实拥有了思考机器。但那只是一个更具启发性的概念。

好的，这是为您转录和整理的中文文稿：

### 人工智能的起源与早期探索

人工智能（AI）的灵感可以追溯到20世纪50年代。当时，计算机科学家们开始探索如何利用计算机程序和算法来构建能够执行人类认知任务的程序。1956年，在达特茅斯会议（Dartmouth workshop）上，约翰·麦卡锡（John McCarthy）教授等人首次提出了“人工智能”这个术语。

在20世纪50年代、60年代和70年代，人工智能的研究尚处于早期探索阶段。这一时期出现了逻辑系统（logic systems）和专家系统（expert systems），同时也对神经网络（neuron network）进行了初步的探索。

### 机器学习的兴起

到了20世纪80年代末、90年代以及21世纪初的这段大约20年时间里，机器学习（machine learning）开始崭露头角。机器学习可以被看作是计算机编程与统计学习的结合。

这种结合引入了一个至关重要的概念：纯粹基于规则的程序无法完全模拟人类所想象的计算机所能实现的各种认知能力。因此，我们需要让机器通过学习来识别模式。一旦机器能够学习模式，它就有可能完成更多任务。

例如，如果我们给机器看三只猫的图片，我们期望的不仅仅是它能识别这三只猫，而是它能够识别第四只、第五只、第六只，以及所有其他的猫。这种学习能力，对于人类和许多动物来说都是基础性的。

### 视觉智能与物体识别

作为一名人工智能研究者，我于2000年开始攻读博士学位，正式进入人工智能领域。我属于第一代机器学习研究者，当时我们已经开始研究机器学习，特别是神经网络。尽管当时神经网络的研究还很艰难，正处于所谓的“AI寒冬”（AI winter）时期，公众关注度不高，资金也相对匮乏，但大量的创新思想仍在涌现。

我的研究生涯之所以与现代人工智能的诞生如此紧密相连，有两点至关重要：首先，我选择从视觉智能（visual intelligence）的角度来研究人工智能。人类是高度视觉化的生物，我们的许多智能都建立在视觉感知和空间理解之上，而不仅仅是语言本身。当然，语言和视觉是互补的。

因此，我专注于视觉智能的研究。在我的博士研究和早期教学生涯中，我和我的学生们致力于解决一个“北极星问题”（northstar problem）：物体识别（object recognition）。这是构建感知世界的基础。我们与世界互动，主要是通过识别和理解物体。我们不会以分子级别去理解世界，而是将物体视为一个整体来与之互动，比如拿起一个茶壶，我们不会去想它由多少块陶瓷组成，而是直接将其作为一个物体来操作。

### ImageNet的诞生与深度学习的突破

我曾是早期识别物体识别重要性的研究者之一。然而，在研究过程中，我发现了一个普遍的痛点：许多数学模型，包括神经网络和贝叶斯网络（Bayesian network），缺乏用于训练的数据。

我意识到，人类的学习以及生物的进化，本质上都是一个大数据学习（big data learning）的过程。人类通过持续不断的经验来学习，而生物的进化也是通过与世界互动和体验来完成的。因此，我和我的学生们推测，大数据是实现人工智能的关键但被严重忽视的要素。

基于这一想法，我们在2006年至2007年间启动了ImageNet项目。我们的目标非常宏大，希望收集互联网上所有关于物体的图像数据。当然，当时的互联网规模远小于现在，所以我们认为这个目标并非遥不可及。如今，几个研究生和一个教授来完成这样的项目，听起来确实有些不切实际。

我们非常细致地从互联网上收集了1500万张图片，并构建了一个包含22,000个概念的分类体系。我们借鉴了语言学家在WordNet（一种词典化的词汇系统）上的工作，并将这些概念整合到ImageNet中，然后将其开源给研究社区。我们还每年举办ImageNet挑战赛，鼓励大家参与进来。

2012年是现代人工智能，特别是深度学习（deep learning）诞生的关键时刻。当时，由杰夫·辛顿（Jeff Hinton）教授领导的多伦多大学研究团队，利用ImageNet的大数据和NVIDIA提供的两块GPU，成功开发出了第一个能够显著提升物体识别能力的神经网络算法。虽然未能完全解决问题，但取得了巨大的进展。

### 现代AI的基石

因此，大数据、神经网络和GPU这“三驾马车”的结合，成为了现代人工智能的黄金配方。

如今，我们看到的ChatGPT等人工智能的爆发式发展，其底层技术依然是这三个核心要素。虽然ChatGPT使用了比2012年更复杂的海量文本数据和更先进的神经网络架构，并且需要更多的GPU，但其基本原理与当年ImageNet的突破一脉相承。

好的，这是根据您提供的英文视频字幕转录并整理的高质量中文文稿：

### AI 核心要素

AI 的核心要素至今仍是如此。令人难以置信，我从未听过这个完整的渊源。我喜欢它最初只用了两块 GPU，而现在可能有数十万块，其算力是指数级增长的。而且那两块 GPU，它们是直接购买的，是游戏 GPU，就像人们玩游戏时去游戏商店买的那种。

正如您所说，模型变得越来越智能，这在很大程度上仍然是当前发展的方式。世界上一些增长最快的公司，我几乎都邀请过他们来我的播客，比如 Merkore、Surge 和 Scale，他们都在这样做。他们持续地为实验室提供更多他们最感兴趣的标注数据。

我记得 Scale 的 Alex Wong，在早期阶段，他可能还保留着我给他发的邮件，那时他刚开始创办 Scale。他非常友好，一直给我发邮件说 ImageNet 启发了他创办 Scale。看到这一点我非常高兴。

### 早期 AI 的发展与命名

您刚才分享的另一个让我印象深刻的点是，这是一种极具能动性（high agency）并“直接去做”的典范。这在 Twitter 上是个很流行的梗，就是“你可以直接去做”。当时，您觉得这是推动 AI 发展的必要之举，那时人们普遍称之为机器学习（machine learning）吗？

我认为当时这两个词是互换使用的。我确实记得一些科技公司，我不会点名，但在 2015 年中到 2016 年中，我曾参与过一次谈话，当时一些科技公司避免使用“AI”这个词，因为他们不确定“AI”是否是一个负面词汇。我记得我当时鼓励大家使用“AI”这个词，因为对我来说，这是人类在科学和技术探索中最宏伟的问题之一，我为这个词感到非常自豪。但是的，起初有些人并不确定。

那大约是什么时候，AI 这个概念才被广泛接受的？

我记得大概是 2016 年。

不到十年前。

那是个转折点。一些人开始称之为 AI。但如果你看看硅谷的科技公司，追溯它们的营销用语，我认为大约在 2017 年左右，公司开始自称为 AI 公司。

这太令人难以置信了，世界变化得如此之快。现在你不可能不称自己为一家 AI 公司。

我明白。

大概九年后。

是的。

天哪。在您看来，关于 AI 的早期历史，还有什么人们不了解但您认为很重要的事情，在我们谈论 AI 的未来发展以及您目前的工作之前？

我认为，就像所有历史一样，我深知我因参与了这段历史而受到认可，但其中有无数的英雄和研究者。我们谈论的是几代研究者。在我自己的领域，有太多人启发了我，我在我的书中也谈到了这一点。但我确实觉得我们的文化，尤其是硅谷，倾向于将成就归功于某一个特定的人。虽然这有其价值，但需要记住的是，AI 作为一个领域，至今已有 70 年的历史，我们已经经历了许多代。没有人能够独自走到今天这一步。

### 关于通用人工智能（AGI）的思考

那么，我想问您一个问题。我们似乎总是在一个“通用人工智能”（AGI）的边缘，这是一个人们经常提及的模糊概念。AGI 即将到来，它会接管一切吗？您认为我们距离 AGI 还有多远？您觉得按照目前的轨迹，我们会实现 AGI 吗？我们需要更多的突破吗？您认为当前的方法能让我们实现 AGI 吗？

是的，这是一个非常有趣的概念，Lenny。我不知道是否有人真正定义过 AGI。有很多不同的定义，包括一些人认为的“机器的超能力”，一直到“机器能否成为经济上可行的社会参与者”，换句话说，就是能赚取工资生活。这算是 AGI 的定义吗？

作为一名科学家，我非常认真地对待科学，我进入这个领域是因为我被“机器能否像人类一样思考和做事”这个宏伟的问题所启发。对我来说，这始终是 AI 的北极星。从这个角度来看，我不知道 AI 和 AGI 之间有什么区别。我认为我们在实现部分目标方面做得非常好，包括对话式 AI，但我认为我们还没有完全征服 AI 的所有目标。

而且，我认为我们的先驱，像艾伦·图灵（Alan Turing），我想如果艾伦·图灵今天还在，你问他如何区分 AI 和 AGI，他可能会耸耸肩说：“我早在 20 世纪 40 年代就问过同样的问题了。”

所以，我不想陷入定义 AI 与 AGI 的泥潭。我觉得 AGI 更像是一个营销术语，而不是一个科学术语。作为一名科学家和技术专家，AI 是我的北极星，也是我所处领域的北极星，我很高兴人们给它起任何他们喜欢的名字。

### 未来突破与世界模型

那么，也许这样问：您描述了从 ImageNet 和 AlexNet 到今天的这些关键组成部分。GPU、数据、标注数据，以及模型本身的算法。Transformer 的出现似乎也是这条轨迹上的重要一步。您觉得这些相同的组成部分，能让我们实现“10 倍更智能的模型”，或者实现对整个世界产生颠覆性影响的 AI 吗？还是说我们需要更多的突破？我知道我们将要谈论“世界模型”（world models），我认为这是其中的一个组成部分，但您认为还有其他什么因素是“会达到瓶颈”或者“只需要更多数据、更多算力、更多 GPU”的吗？

哦不，我绝对认为我们需要更多的创新。我认为在扩展数据量、增加 GPU 数量以及构建更大的模型架构方面，还有很多工作要做。但我绝对认为……

好的，这是根据您提供的英文视频字幕转录并整理的高质量中文文稿：

### AI 创新的无限可能

我们认为需要更多的创新。纵观人类历史，没有任何一门严谨的科学学科曾宣称“我们已经完成了，创新到此为止”。而人工智能（AI）是人类文明中最年轻的科学技术领域之一，我们才刚刚触及皮毛。

### AI 的局限性与世界模型的必要性

举个例子，正如我之前提到的，今天我们将深入探讨“世界模型”（World Models）。如果我们让一个模型去识别一段办公室的视频，并要求它数出有多少把椅子，这本是蹒跚学步的孩童或小学就能做到的事情，但目前的 AI 却无法做到。

AI 目前还有太多做不到的事情。更不用说，像艾萨克·牛顿（Isaac Newton）那样，观察天体运行并推导出支配万物运动的方程组，那种创造力、外推能力和抽象能力，我们目前根本无法让 AI 实现。

再来看看情商。想象一个学生走进老师办公室，谈论学习动力、热情、该学什么，以及困扰他们的问题。即使是当今最先进的对话机器人，也无法提供这种水平的情感和认知智能。因此，我们还有很多可以改进的地方。我不认为我们已经停止创新了。

### AGI 的遥远距离

最近，DeepMind 的 Demis Hassabis 在一次采访中被问及，他认为通用人工智能（AGI）还有多远，以及 AGI 最终会是什么样子。他的回答很有趣：如果我们把 20 世纪末之前的所有信息都提供给最先进的模型，看看它是否能推导出爱因斯坦的所有突破性发现，那么我们离这个目标还非常遥远。

事实上，情况可能更糟。如果我们把牛顿当年没有的、包括现代天文观测数据在内的所有数据都提供给 AI，并要求它推导出 17 世纪关于物体运动定律的那一套方程组，今天的 AI 也无法做到。

**主持人**：所以，您的意思是，我们离 AGI 还有很长的路要走？

**嘉宾**：是的。

### 世界模型：AI 的下一个前沿

**主持人**：好的，那我们来谈谈“世界模型”（World Models）。在我看来，这又是一个您超前于时代的绝佳例子。您很早就认识到，AI 和神经网络需要大量干净的数据来学习。您一直在谈论“世界模型”这个概念，并且您创办了一家公司来构建它。这与语言模型不同，它是一个“世界模型”。我们稍后会讨论它到底是什么。

现在，埃隆·马斯克（Elon Musk）和黄仁勋（Jensen Huang）都在谈论“世界模型”，我也知道谷歌也在研究这个领域。您在这方面已经深耕多年，并且最近还推出了一项新产品，我们将在播客播出前进行讨论。请您谈谈，“世界模型”到底是什么？为什么它如此重要？

**嘉宾**：我很高兴看到越来越多的人，比如埃隆和黄仁勋，开始关注“世界模型”。我一生都在思考如何推动 AI 的发展。过去几年里，来自研究界以及 OpenAI 等公司的“大型语言模型”（Large Language Models）对我这样的研究者来说，都极具启发性。

我记得 GPT-2 在 2020 年底发布的时候，我当时是斯坦福大学人类中心人工智能研究所（Stanford's Human-Centered AI Institute, HAI）的联合主任。公众当时还没有意识到大型语言模型的强大威力，但作为研究者，我们已经看到了它的潜力，看到了未来。

我曾与我的自然语言处理（NLP）领域的同事，如 Percy Leang 和 Chris Batting，进行了深入的交流，我们讨论了这项技术将是多么关键。斯坦福 HAI 是第一个建立“基础模型”（Foundation Model）研究中心的学术机构。Percy Leang 和许多研究者发表了第一篇关于“基础模型”的学术论文。这一切都对我产生了巨大的启发。

### 从语言到空间智能

我本人来自视觉智能领域，我一直在思考，除了语言之外，还有哪些领域可以取得巨大的进步。因为人类利用我们的空间智能和对世界的理解能力，完成了无数事情，而这些能力超越了语言。

想象一下一个混乱的紧急救援现场，比如火灾、交通事故或自然灾害。如果你身临其境，思考人们是如何组织起来进行救援、阻止灾难蔓延、扑灭大火的。这其中很大一部分是关于运动、对物体和世界的自发理解，以及情境意识。语言是其中的一部分，但很多情况下，语言无法帮助你扑灭大火。

我一直在思考这些问题。同时，我还在进行大量的机器人研究。我突然意识到，连接除了语言之外的智能，以及连接“具身智能”（Embodied AI），也就是机器人，连接视觉智能的关键，就是这种关于理解世界的空间智能。

### World Labs 的诞生

大约在 2024 年，我做了一个关于空间智能和世界模型的 TED 演讲。我开始形成这个想法，这基于我多年的机器人和计算机视觉研究。有一点对我来说非常明确：我希望能与最优秀的科技人才合作，并以最快的速度将这项技术变为现实。

于是，我们创立了一家名为 World Labs 的公司。正如您所见，“World”（世界）这个词就在其中。

好的，作为资深内容编辑和翻译专家，我将为您将这段英文视频字幕转录为高质量、易读的中文文稿。

---

### 世界模型与空间智能

**主持人**: 我们公司的名称之所以选择“World Models”，是因为我们对世界建模（world modeling）和空间智能（spatial intelligence）深信不疑。很多人习惯了聊天机器人（chatbots），它们本质上是大型语言模型（Large Language Models）。简单理解世界模型，就是你描述一个场景，它就能生成一个可以无限探索的世界。我们稍后会提供相关链接，但你觉得这是对世界模型的一个简单理解吗？

**嘉宾**: Lenny，这只是其中一部分。我认为，理解世界模型的简单方式是，它能让任何人在脑海中创造出任何世界，只需通过提示（prompting），无论是图像还是文字。同时，也能在这个世界中进行互动。你可以浏览、行走、拾取物品，或者改变事物。更重要的是，还能在这个世界中进行推理。

举个例子，如果消费世界模型输出的“代理”（agent）是一个机器人，它就应该能够规划自己的路径，并帮助完成一些任务，比如整理厨房。所以，世界模型是一个基础，你可以用它来推理、互动和创造世界。

### 机器人的未来与关键缺失

**主持人**: 很好。机器人似乎是人工智能研究者们下一个巨大的焦点，以及它对世界的影响。你的意思是，这是让机器人真正能在现实世界中工作的关键缺失环节——理解世界是如何运作的。

**嘉宾**: 是的。首先，我认为除了机器人，还有更多令人兴奋的领域。但我同意你刚才说的所有内容。我认为世界建模和空间智能是“具身人工智能”（embodied AI）的关键缺失环节。

同时，我们也不能低估人类本身就是具身代理。AI的智能可以增强人类，就像今天人类是语言动物，但我们在语言任务（包括软件工程）上得到了AI的极大增强一样。我认为，我们不应低估，或者说我们往往忽略了，人类作为具身代理，可以从世界模型和空间智能模型中获益良多，机器人也是如此。

这里有几个重大的突破点：机器人，这是一个巨大的议题。如果这能实现，想象一下我们每个人都有机器人为我们做各种事情。它们可以进入灾区，帮助我们处理灾难等。游戏显然也是一个非常酷的例子，就像你可以凭空创造出无限可玩的游戏。

### 创意、设计与科学发现

**嘉宾**: 此外，还有创造力。感觉就像是玩乐、发挥创意、构思全新的奇妙世界和环境。还有设计，人类的设计涵盖了从机器到建筑再到房屋的方方面面。

当然，还有科学发现。我喜欢用DNA结构发现的例子。在DNA发现史上，最重要的证据之一是Rosalyn Franklin拍摄的X射线衍射照片。那是一张二维的平面照片，显示了一个类似十字架的衍射图案。你可以去谷歌搜索这些照片。

但就是这张二维照片，人类，特别是两位重要人物James Watson和Francis Crick，结合其他信息，能够进行三维空间的推理，并推断出DNA高度三维的双螺旋结构。这个结构绝对不可能是二维的。你无法用二维思维去推断出这个结构，你必须运用人类的空间智能进行三维空间思考。所以我认为，即使在科学发现领域，空间智能或AI辅助的空间智能也是至关重要的。

### “玩具”的颠覆力量

**主持人**: 这就像Chris Dixon曾说过的一句话：下一个大事件，最初看起来会像个玩具。当ChatGPT刚出来时，我记得Sam Altman发推说：“这是我们正在玩的一个很酷的东西，来看看吧。”现在它已经成为历史上增长最快的、改变了世界的产品。

**嘉宾**: 是的。

**主持人**: 很多时候，那些看起来“哦，这个很有趣，玩起来很开心”的东西，最终却能改变世界。

**嘉宾**: 是的。

### [广告] Cinch 客户通信云

**主持人**: 本期节目由 Cinch 客户通信云（Cinch, the customer communications cloud）赞助播出。关于数字客户沟通，有这么一件事：无论你是发送营销活动、验证码还是账户提醒，你都需要它们可靠地送达用户。这就是 Cinch 发挥作用的地方。

全球超过 15 万家企业，包括全球十大科技公司中的八家，都使用 Cinch 的 API 将消息、邮件和通话功能集成到他们的产品中。而消息传递领域正发生着一件大事，产品团队需要了解。

那就是富通信服务（Rich Communication Services），简称 RCS。你可以把 RCS 想象成 SMS 2.0。用户不再收到来自陌生号码的短信，而是会看到你经过验证的公司名称和 Logo，而且无需下载任何新东西。这是一种更安全、更具品牌效应的体验。此外，你还可以获得交互式轮播（interactive carousels）和建议回复（suggested replies）等功能。

这为什么重要？因为美国运营商正开始采用 RCS。Cinch 已经在帮助各大品牌在全球发送 RCS 消息，并且他们正在帮助 Lenny 的播客听众，在 US 市场被海量信息淹没之前，率先完成注册。

想了解更多，请访问 get started at cinch.com/lenny。拼写是 s i nch.com/lenny。

### “苦涩教训”与机器人局限

**主持人**: 我联系了 Ben Horowitz，他非常欣赏你的工作，是你的忠实粉丝。我相信他们也是你们的投资者。

**嘉宾**: 是的，我们认识很多年了，但目前他们确实是 World Labs 的投资者。

**主持人**: 太棒了。我问他我应该问你什么，他建议我问你：为什么“苦涩教训”（the bitter lesson）单独来看，不太可能让机器人成功？首先，请解释一下AI历史上的“苦涩教训”是什么，然后说明为什么它无法让我们在机器人领域达到目标。

**嘉宾**: 嗯，首先，有很多“苦涩教训”。

---

好的，这是根据您提供的英文视频字幕转录并整理的中文文稿：

### AI的“苦涩教训”与数据的作用

大家常提到的“苦涩教训”（bitter lessons）源自一篇由近期图灵奖得主 Richard Sutton 发表的论文。他在强化学习领域有深入研究，并指出，纵观人工智能算法发展的历史，尤其是在算法发展方面，**数据量庞大的简单模型最终总是胜出**，而非数据量较少但模型更复杂的那些。

这篇论文的发表时间甚至晚于 ImageNet 的出现。对我而言，ImageNet 的出现并非“苦涩”，而是一个“甜蜜的教训”。正因如此，我才创立了 ImageNet，因为我深信海量数据扮演着至关重要的角色。

### 机器人领域的“苦涩教训”挑战

那么，为什么“苦涩教训”在机器人领域单独来看会遇到困难呢？首先，我们必须承认，机器人技术目前仍处于非常初期的实验阶段。其研究成熟度远不如语言模型。

许多研究人员仍在尝试各种不同的算法，其中一些算法确实依赖于海量数据。因此，我认为海量数据在机器人领域将继续发挥作用。

### 机器人数据获取的难题

但机器人领域面临着一些挑战，其中一个关键问题是**数据获取的难度**。获取数据要困难得多。有人可能会说，网络上有海量数据，而最新的机器人研究也确实利用了网络视频。

我认为网络视频确实发挥了一定作用。但如果我们思考一下，是什么让语言模型取得了成功？作为一名从事计算机视觉、空间智能和机器人研究的人，我非常羡慕我的语言模型领域的同行。

### 语言模型与机器人模型的训练差异

他们拥有一个完美的训练环境：训练数据是词语，最终转化为标记（tokens），然后模型输出的也是词语。这样，你期望得到的结果（我们称之为目标函数）与你的训练数据之间就实现了完美的对齐。

然而，机器人领域则不然，空间智能领域也是如此。你希望机器人能够执行动作（actions）。但你的训练数据中缺乏三维世界中的动作。而这正是机器人必须要做的事情——在三维世界中执行动作。

因此，我们不得不寻找不同的方法来“将方块塞进圆孔”（fit a square in a round hole）。我们拥有大量的网络视频，然后我们就必须开始讨论如何通过补充数据来完善，例如远程操作数据（teleoperation data）或合成数据（synthetic data），以便机器人能够基于“苦涩教训”——即海量数据——进行训练。

### 世界模型在机器人领域的潜力

我认为仍然存在希望，因为我们目前在**世界模型（world modeling）**方面所做的工作，将极大地解锁机器人领域的信息。但我认为我们必须谨慎，因为我们仍处于这个领域的早期阶段，“苦涩教训”的真正检验尚未到来，因为我们还没有完全解决数据的问题。

### 机器人作为物理系统的复杂性

关于机器人领域的“苦涩教训”的另一个方面，我认为我们应该非常现实地认识到：与语言模型甚至空间模型相比，机器人是**物理系统**。

机器人更接近于自动驾驶汽车，而不是大型语言模型。这一点非常重要。这意味着，为了让机器人正常工作，我们不仅需要“大脑”（即算法和模型），还需要**物理实体（physical body）**，还需要**应用场景（application scenarios）**。

### 自动驾驶汽车的漫长历程

如果我们回顾自动驾驶汽车的历史，我的同事 Sebastian Thrun 在 2005 年或 2006 年带领斯坦福大学的汽车赢得了第一次 DARPA 挑战赛。从那时起，原型自动驾驶汽车能够在内华达沙漠中行驶 130 英里，到现在 Waymo 在旧金山街头运行，已经过去了 20 年，而我们甚至还没有完成。

这已经是一个 20 年的旅程了。而且，自动驾驶汽车是更简单的机器人，它们只是在二维平面上运行的金属盒子，目标是不触碰任何东西。而机器人是三维物体，在三维世界中运行，目标是触碰物体。

因此，这段旅程将会充满各种各样的方面和元素。当然，有人可能会说，自动驾驶汽车早期的算法是在深度学习出现之前。所以，深度学习正在加速“大脑”的进步，我认为这是事实。

### 机器人与汽车行业的成熟度对比

这也是我投身机器人和空间智能领域，并对此感到兴奋的原因。但与此同时，汽车行业已经非常成熟，产品化也涉及到成熟的用例、供应链和硬件。

所以我认为，现在是解决这些问题的一个非常有趣的时期。但确实，Ben 说得对，我们在进行这项工作时，可能仍然会遇到一系列“苦涩的教训”。

### 对人脑的敬畏之心

**主持人**：在做这项工作时，你是否会因为人脑的工作方式而感到敬畏，它能为我们完成所有这一切？仅仅是让一台机器能够四处走动而不撞到东西或摔倒的复杂性，是否让你对我们已经拥有的能力更加赞叹？

**嘉宾**：完全正确。我们仅依靠大约 20 瓦的功率就能完成如此多的事情，这比我此刻所在的房间里的任何一个灯泡都要暗。因此，我认为，我越是从事人工智能工作，就越是尊重人类。

### Marbo 产品介绍

**主持人**：让我们来谈谈你刚刚推出的这款产品，它叫做 Marbo，名字很可爱。请谈谈它是什么，为什么它很重要。我试用过它，它太棒了。我们会提供链接供大家查看。Marbo 是什么？

**嘉宾**：是的，我非常兴奋。首先，Marbo 是 World Labs 推出的首批产品之一。World Labs 是一家前沿模型公司（frontier model company）。我们由四位联合创始人创立，他们在技术领域有着深厚的历史。我的联合创始人 Justin Johnson、Kristoff Lassner 和 Ben Mildenhal，我们都来自人工智能、计算机图形学和计算机视觉的研究领域。

我们相信，空间智能和世界模型（world modeling）与语言模型同等重要，甚至更重要，并且是语言模型的补充。因此，我们希望抓住这个机会，创建一个深入的技术研究实验室，能够连接前沿模型与产品之间的纽带。Marbo 是基于我们的前沿模型构建的一款应用程序。我们花费了一年多的时间来构建它。

好的，这是根据您提供的英文视频字幕转录并整理的高质量中文文稿：

### AI教母谈论工作、机器人与世界模型

**嘉宾**：Dr. Fei-Fei Li

**主持人**：世界首个能够生成真正三维世界的生成模型。这是一个非常非常困难的问题，而且过程也极其艰辛。我们拥有一支由技术精湛的创始团队组成的队伍。

**嘉宾**：大约一两个月前，我们首次实现了仅通过一个句子和一张或多张图片，就能生成可供导航的世界。如果将其置于VR设备中，您甚至可以四处行走。尽管我们为此投入了很长时间，但这一成果依然令人振奋，我们希望能将其交到需要它的人手中。

**嘉宾**：我们知道，许多创作者、设计师，以及那些研究机器人模拟、可交互、可沉浸式世界不同应用场景的人，还有游戏开发者，都会觉得它很有用。因此，我们开发了Marble，作为第一步。它仍处于非常早期阶段，但它是世界上第一个实现这一功能的模型，也是第一个允许用户通过“提示生成世界”（prompt to worlds）来创造世界的。

**主持人**：我试用了一下，简直太不可思议了。你可以创造一个微小的世界，在其中无限行走，比如在《指环王》的中洲，虽然目前还没有人，但它真的太令人惊叹了，你可以去任何地方。我看到了很多例子，比如一个反乌托邦的世界。

**嘉宾**：是的。我最喜欢的部分是，你有时可以看到世界在渲染出所有纹理之前，以点状的形式呈现出来。我喜欢这样，它让你得以一窥模型内部的工作机制。

**主持人**：这太棒了。作为研究者，我从中学习到很多。那些引导你进入世界的点，其实是一个故意的可视化设计，并非模型本身的一部分。模型实际上只是生成世界。我们试图找到一种引导用户进入世界的方式，几位工程师尝试了不同的版本，最终我们选择了这种点状引导。许多用户都表示这种体验非常令人愉悦，这让我们感到非常欣慰，因为这个并非核心模型部分的可视化设计，竟然让我们的用户如此开心。

**嘉宾**：哇，你们加入这个是为了让用户更容易理解模型的工作原理，并获得更好的体验。这太有趣了。这让我想起了大型语言模型（LLM），虽然不是一回事，但它们也会谈论自己的思考和行动。

**主持人**：是的，确实如此。

**嘉宾**：这也让我想起了《黑客帝国》。这简直就是《黑客帝国》的体验。不知道这是否是你们的灵感来源？

**主持人**：嗯，正如我所说，很多工程师都为此付出了努力，这可能是他们的灵感来源，它存在于他们的潜意识中。

**嘉宾**：好的。那么，对于那些想要尝试使用它的人来说，今天有哪些实际的应用场景？你们这次发布的目的是什么？

**主持人**：是的。我们相信世界建模（world modeling）是一个非常通用的技术，并且已经看到了一些非常令人兴奋的应用。例如，在电影的虚拟制作领域。他们需要三维世界来与摄像机对齐，这样当演员表演时，他们就能很好地定位摄像机并拍摄片段。

**嘉宾**：我们已经看到了令人难以置信的应用。事实上，我不知道你是否看到了我们发布Marble的视频，它是由一家虚拟制作公司制作的。我们与索尼合作，他们利用Marble拍摄了那些视频。我们的技术艺术家和导演告诉我们，这将他们的制作时间缩短了40倍。

**主持人**：确实如此。事实上，我们只有一个月的时间来完成这个项目，而且他们需要拍摄的内容非常多。所以，使用Marble极大地加速了虚拟制作在视觉特效和电影领域的生产效率。这是其中一个用例。

**嘉宾**：我们已经看到用户将Marble场景中的网格导出，并将其用于游戏开发，无论是VR游戏还是其他类型的游戏。我们还展示了一个机器人模拟的例子。因为在我（以及现在依然）进行机器人训练的研究中，最大的痛点之一是创建用于训练机器人的合成数据。

**主持人**：这些合成数据需要非常多样化，需要来自不同的环境，包含不同的可操作对象。一种方法是让计算机进行模拟，否则就需要人类手动构建所有资产，这会耗费更长的时间。因此，我们已经有研究人员联系我们，希望使用Marble来创建这些合成环境。

**嘉宾**：我们还收到了意想不到的用户需求。例如，一个心理学团队联系我们，希望使用Marble进行心理学研究。他们发现，他们研究的一些精神疾病患者，需要了解大脑对不同沉浸式场景（如混乱场景或整洁场景等）的反应。

**主持人**：研究人员很难获得这些沉浸式场景，而且创建它们需要花费太长时间和太多预算。而Marble几乎可以即时生成大量的实验场景。

好的，这是为您转录和整理的中文文稿：

### AI 领域的新应用

目前，我们看到了多种使用场景。视觉特效（VFX）、游戏开发者、模拟软件开发者以及设计师们都对此表现出极大的热情。

### AI 产品发布的策略

在 AI 领域，产品发布通常是这样的：尽早将产品推向市场，以便发现最大的应用场景。OpenAI 的 CEO 曾告诉我，当他们首次发布 ChatGPT 时，他会浏览 TikTok，观察人们如何使用它，以及他们讨论的内容。这些观察让他们确信了应该在哪方面投入更多精力，并帮助他们了解用户实际想要如何使用这款产品。

我特别喜欢其中一个关于心理治疗的应用场景。我能想象到，对于那些有恐高症、害怕蛇或蜘蛛的人来说，这可能会非常有帮助。一位朋友昨晚就打电话给我，谈论了他对高度的恐惧，并问我是否可以使用 Marble。这真是太棒了。

### Marble 与其他视频生成模型的区别

您直接提到了这个点。这让我想到，很多人会疑问，Marble 与 V3 以及其他视频生成模型有什么区别？对我来说答案很清晰，但或许有必要解释一下，Marble 与市面上其他视频 AI 工具的不同之处。

Marble 的核心理念是“空间智能”（Spatial Intelligence）至关重要。空间智能不仅仅是关于视频。事实上，世界并非被动地观看视频掠过，对吧？我喜欢柏拉图在《理想国》中提出的“洞穴寓言”（Allegory of the Cave）来描述视觉。他设想一个被绑在椅子上的囚犯，在一个洞穴里，看着面前的墙壁上演着一场全息戏剧。但实际上，真实的戏剧演员在他身后表演，光线投射出影像在洞穴的墙壁上。囚犯的任务就是弄清楚发生了什么。这是一个相当极端的例子，但它很好地说明了视觉的本质。

视觉的本质是为了从二维（2D）的感知中理解三维（3D）甚至四维（4D）的世界。对我而言，空间智能比仅仅创造一个平面的二维世界要深刻得多。空间智能是创造、推理、互动、理解深度空间世界的能力，无论是二维、三维还是四维，包括其中的动态变化。因此，Marble 正是专注于此。

当然，生成视频本身也可以是这项能力的一部分。事实上，就在几周前，我们展示了世界上首个在单个 H100 GPU 上实现的实时可演示的视频生成技术。这部分技术也包含在我们的产品中。但我认为 Marble 的与众不同之处在于，我们真正希望创作者、设计师和开发者能够获得一个能够赋予他们三维结构世界的模型，以便他们能将其用于工作。这就是 Marble 的独特性所在。

### Marble 的平台潜力

在我看来，Marble 是一个能够支持大量创新应用的平台。正如您所描述的，视频可能只是一个一次性的、有趣且酷炫的产物，然后就结束了。

顺带一提，在 Marble 中，我们也允许用户导出为视频格式。所以，就像您说的，您可以进入一个世界——比如一个霍比特人的洞穴——然后，特别是作为创作者，您可以以一种导演心中特有的轨迹来移动摄像机，然后将这段内容从 Marble 导出为视频。

### 创建 Marble 的投入

要创建这样的产品，需要付出多少努力？团队规模有多大？使用了多少 GPU？您能分享一些关于您所发布的产品所需投入的信息吗？我不知道有多少信息是保密的，但我想了解一下创建这样一个产品需要什么。

这需要大量的脑力。我们常说，每颗大脑的功耗是 20 瓦。从这个角度看，这个数字很小。但实际上，这背后蕴含着半个多世纪的进化才赋予我们这样的能力。我们目前有一个大约 30 人的团队，其中绝大多数是研究人员和研究工程师，但我们也有设计师和产品经理。我们坚信要打造一家以空间智能的深度技术为根基的公司，同时我们也在构建真正的产品。因此，我们实现了研发与产品化的融合。当然，我们使用了大量的 GPU，这是技术上的必需。

### 创始人经历与创业感悟

我很高兴听到这些。恭喜您和您的团队成功发布。我知道这是一个巨大的里程碑，付出了巨大的努力。

让我们来谈谈您的创业历程。您是这家公司的创始人。您是什么时候开始创业的？几年前？两三年？

一年。

一年。好的。

18 个月。

好的。如果能回到 18 个月前，您有什么话想对当时的自己说？有什么是您希望自己提前知道的？

我一直希望自己能预知技术的未来。我认为，我们能够比大多数人更早地看到技术发展的方向，这正是我们创业的优势之一。但即便如此，未知和即将到来的事物仍然是如此令人兴奋和惊叹。不过，我知道您问这个问题并非仅仅关于技术未来。您可能更想了解……我不是在 20 岁就开始创立如此规模的公司。所以……

好的，这是根据您提供的英文视频字幕转录并整理成的中文文稿：

### 创业与竞争

我19岁时曾在干洗店工作，但那规模小多了。我们之后可以聊聊。后来我创立了Google Cloud AI，又在斯坦福大学创立了一个研究所，但它们是不同的“物种”。相比于那些年轻的创业者，我觉得自己在经历创业的艰辛旅程时，准备得更充分一些。

但我仍然感到惊讶，有时甚至会让我感到一丝焦虑，那就是人工智能领域的竞争是多么激烈。这种竞争不仅体现在技术本身，也体现在人才方面。当我创立公司时，我们从未想过某些人才的薪酬会如此之高。这些事情持续地让我感到意外，我必须时刻保持警惕。

**问**：您提到的竞争，是指对人才的争夺，以及事物发展的速度吗？

**答**：是的。

### 职业生涯的驱动力

**主持人**：您提到了一个我想深入探讨的点。回顾您的职业生涯，您似乎一直身处那些促成了如今许多重大突破的关键人物和团队之中。我们谈到了ImageNet，也谈到了斯坦福大学的SAIL（人工智能实验室），在那里发生了许多工作；还有Google Cloud，也取得了许多突破。是什么让您走到这些地方的？对于那些希望在职业生涯中进步、站在未来前沿的人来说，是否存在一种贯穿始终的、将您从一个地方引向另一个地方、将您拉入那些团队的“拉力”，这对人们来说可能很有启发？

**嘉宾**：是的，这是一个非常好的问题，Lenny。因为我确实经常思考这个问题。显而易见，是好奇心和对人工智能的热情将我带入了AI领域。这更像是一个科学上的北极星，我并不在意AI是否真的会成为一个热门事物。

那么，我如何选择我工作过的特定地方，包括创立World Labs呢？我想我非常感激自己，或者说感激我父母的基因。我是一个在智力上非常无畏的人。我必须说，当我招聘年轻人的时候，我也会寻找这种特质。因为我认为，如果你想做出改变，这是一种非常重要的品质。当你想要做出改变时，你必须接受你正在创造一些新的东西，或者正在深入研究一些新的领域，而这些事情是人们从未做过的。

如果你有这种自我认知，你就几乎必须允许自己变得无畏和勇敢。所以，例如，当我来到斯坦福大学时，在学术界，我离“终身教职”（tenure）非常近了，这意味着在普林斯顿大学（我的母校）我将获得一份永久的工作。但我选择了来斯坦福，因为我热爱普林斯顿。只是在那一刻，斯坦福有那么多优秀的人才，硅谷的生态系统也如此出色，以至于我愿意冒着重新计算我的终身教职时钟的风险。

我成为了SAIL（人工智能实验室）的第一位女性主任，当时我相对而言还是一名非常年轻的教员。我之所以想这样做，是因为我关心那个社群。我没有花太多时间去考虑所有可能的失败情况。当然，我非常幸运，得到了资深教员的支持，但我就是想做出一些改变。

然后去Google也是类似的。我想和Jeff Dean、Geoff Hinton以及所有这些杰出的人才一起工作。在World Labs也是如此。我怀有这份热情，并且我相信拥有相同使命感的人能够成就非凡。这就是它如何指引我的人生。我不会过度思考所有可能出错的事情，因为那样的事情太多了。

**主持人**：我觉得这是其中一个重要的方面，就是不关注负面因素，而是更多地关注人、关注使命。是什么让您感到兴奋？您认为……

**嘉宾**：是的，我确实想对所有AI领域的年轻人才、工程师、研究者说一句话，因为有些人申请了World Labs。我感到非常荣幸您考虑了World Labs。我确实发现，如今许多年轻人会考虑求职时的每一个细节。也许，也许这就是他们想要的方式。但有时，我确实想鼓励年轻人关注那些真正重要的事情。

因为我发现，在与求职者交流时，我经常处于一种指导模式。不是在招募或不招募，而是在指导。当我看到一个优秀的年轻人才，他过度关注考虑一份工作的每一个细微的维度和方面时，也许最重要的事情是：你的热情在哪里？你是否认同这个使命？你是否相信并信任这个团队？

然后，仅仅关注你能够带来的影响，以及你能够与之共事的工作和团队。

**主持人**：这确实很难。对于现在AI领域的人来说，这很难。他们面临着太多信息，太多新闻，太多动态，太多“错失恐惧症”（FOMO）。

**嘉宾**：这是真的。

**主持人**：我能感受到那种压力。所以，我认为这个建议非常重要。就是什么东西能让你真正感到满足，而不是仅仅考虑“哪里是发展最快的公司？”“谁会赢？”我不知道。

### 人类中心AI研究所（HAI）

**主持人**：我想确保问您关于您今天在斯坦福大学HAI（人类中心AI研究所）所做的工作。

**嘉宾**：您在那里做什么？我知道这是您还在做的事情。

**嘉宾**：是的，HAI（人类中心AI研究所）是我和一群教员，比如John Hendy教授、James Landy教授、Chris Manning教授，在2018年共同创立的。我当时正好完成了我的最后一个……

好的，作为一位资深内容编辑和翻译专家，我将为您将这段英文视频字幕转录为高质量、易读的中文文稿。

---

**视频标题：AI教母谈论工作、机器人与“世界模型”的未来 | 李飞飞博士**

### 斯坦福HAI的创立与愿景

我在谷歌（Google）度过了一段休假时光。那对我来说是一个非常非常重要的决定，因为我本可以继续留在工业界。然而，在谷歌的这段经历让我深刻认识到，人工智能（AI）将是一项关乎文明发展的技术。我意识到这件事对人类的重要性，以至于我在2018年于《纽约时报》（New York Times）发表了一篇文章，呼吁建立一个指导框架来开发和应用AI。

这个框架必须以人类的仁善和以人为本为核心。我深感斯坦福大学——作为硅谷腹地世界顶尖学府之一，孕育了英伟达（Nvidia）和谷歌（Google）等重要企业——应该成为思想领袖，创建这个以人为本的AI框架，并将其体现在我们的研究、教育、政策和生态系统工作中。

因此，我创立了HAI（Human-Centered Artificial Intelligence Institute）。如今，经过六七年的发展，它已成为全球最大的AI研究所，致力于在以人为本的AI研究、教育、生态系统推广和政策影响方面做出贡献。

### HAI的跨学科合作与政策影响力

HAI汇聚了斯坦福大学所有八个学院的数百名教职员工，涵盖医学、教育、可持续发展、商业、工程、人文学科和法律等领域。我们支持跨学科领域的研究人员，从数字经济、法律研究到政治科学，再到新药发现，以及超越Transformer的新算法研究。

我们还非常重视政策方面的工作。HAI成立之初，我意识到硅谷与华盛顿特区、布鲁塞尔或其他地区之间缺乏沟通。鉴于AI技术的重要性，我们需要让所有人参与进来。因此，我们创建了多个项目，如国会训练营（Congressional Boot Camp）、AI指数报告（AI Index Report）和政策简报会。

我们积极参与政策制定，包括倡导一项在美国第一任特朗普政府时期通过的国家AI研究云法案（National AI Research Cloud bill），并参与了州一级的AI监管讨论。我们做了很多工作，我本人也持续作为领导者之一，尽管我已不再深入参与日常运营。因为我不仅关心我们创造这项技术，更关心我们是否能以正确的方式使用它。

### 访谈：AI与个人角色的未来

**主持人：** 哇，我之前并不知道您在做所有这些其他工作。您刚才谈论的时候，我突然想起查理·芒格（Charlie Munger）有句名言：“拿一个简单的想法，并极其认真地对待它。” 我觉得您在很多方面都做到了这一点，并且坚持了下来，您多年来在这么多领域产生的巨大影响真是令人难以置信。我将跳过闪电问答环节，只问您最后一个问题。您还有什么想分享的吗？有什么想留给听众的吗？

**嘉宾：** 我对AI感到非常兴奋，Lenny。我想回答一个我在世界各地旅行时，每个人都会问我的问题：如果我是一名音乐家、一名中学老师、一名护士、一名会计师、一名农民，我是否在AI中有角色？还是AI将完全取代我的生活或工作？

我认为这是AI最重要的问题。我发现，在硅谷，我们往往不与“我们这样的人”以及“不像我们这样的人”进行心与心的交流，而是与所有“我们”交流。我们倾向于随意抛出“无限生产力”、“无限闲暇时间”或“无限权力”等词汇。但归根结底，AI是关于人的。

当人们问我这个问题时，我的回答是响亮的“是”。每个人在AI中都有角色。这取决于你做什么以及你想要什么。但没有任何技术应该剥夺人的尊严。人的尊严和自主性应该是所有技术开发、部署和治理的核心。

所以，如果你是一位热爱讲故事的年轻艺术家，拥抱AI作为一种工具。事实上，我希望它能成为你的工具。因为你讲故事的方式是独特的，世界仍然需要它。但你如何讲述你的故事，如何利用最令人难以置信的工具以最独特的方式讲述你的故事，这很重要，而且这种声音需要被听到。

如果你是一位即将退休的农民，AI仍然很重要，因为你是一名公民。你可以在你的社区中发挥作用。你应该在AI如何被使用、如何被应用的问题上拥有发言权。你与人合作，你可以鼓励你们所有人使用AI来让生活更轻松。

如果你是一名护士，我希望你知道，至少在我看来，我在医疗保健研究方面付出了很多努力，因为我认为我们的医护人员应该得到AI技术的极大增强和帮助，无论是通过智能摄像头提供更多信息，还是通过机器人辅助。因为我们的护士已经过度劳累、身心俱疲。随着社会老龄化，我们需要更多帮助来照顾人们。AI可以扮演这个角色。

所以，我想说的是，即使像我这样的技术专家，也必须真诚地认识到，每个人在AI中都有角色。

### 结束语与联系方式

**主持人：** 这是多么美妙的结束方式。这完美地呼应了我们开始时谈到的——这取决于我们，以及我们每个人为AI在我们生活中的作用承担个人责任。最后一个问题，人们在哪里可以找到Marble？他们可以去哪里？也许他们想尝试加入World Labs？网站是什么？人们去哪里？

**嘉宾：** World Labs的网站是 www.worldlabs.ai。你可以在那里找到我们的研究进展，我们有技术博客。你可以在那里找到Marble产品，可以注册登录。你可以在那里找到我们的招聘信息链接。我们位于旧金山，我们渴望与世界上最优秀的人才合作。

**主持人：** 太棒了！Fay，非常感谢您来到这里。

**嘉宾：** 谢谢你，Lenny。

**主持人：** 再见，各位。

---

好的，作为资深内容编辑和翻译专家，我将为您将英文视频字幕转录为高质量、易读的中文文稿。

---

**视频标题：人工智能教母谈论工作、机器人与“世界模型”的未来 | Dr. Fei-Fei Li**

---

**【节目收尾与订阅指引】**

非常感谢您的收听。如果您觉得本期节目有价值，欢迎在 Apple Podcasts、Spotify 或您常用的播客应用上订阅我们的节目。

**【听众互动与支持】**

同时，也请您考虑给我们一个评分或留下评论，这对于帮助更多听众发现我们的播客非常有益。

**【节目信息获取】**

您可以在 lennispodcast.com 上找到所有往期节目或了解更多关于本节目的信息。

**【期待下次相见】**

我们下期节目再见。

---

## 英文原文

A lot of people call you the godmother of AI. The work you did actually was the spark that brought us out of AI winter >> in the middle of 2015, middle of 2016. Some tech companies avoid using the word AI because they were not sure if AI was a dirty word. 2017ish

was the beginning of companies calling themselves AI companies. >> There's this line, I think this was when you were presenting to Congress, there's nothing artificial about AI. It's inspired by people. It's created by people. And most importantly, it impacts

people. >> It's not like I think AI will have no impact on jobs or people. In fact, I believe that whatever AI does currently or in the future is up to us. It's up to the people. I do believe technology is a net positive for humanity. But I think

every technology is a double-edged sword. If we're not doing the right thing as a society, as individuals, we can screw this up as well. you had this breakthrough insight of just okay we can train machines to think like humans but it's just missing the data that humans

have to learn as a child >> I chose to look at artificial intelligence through the lens of visual intelligence because humans are deeply visual animals we need to train machines with as much information as possible on images of objects but objects are very

very difficult to learn a single object can have infinite possibilities that is shown on an image in order To train computers with tens and thousands of object concepts, you really need to show it millions of examples.

Today, my guest is Dr. Feay Lee, who's known as the godmother of AI. Feet has been responsible for and at the center of many of the biggest breakthroughs that sparked the AI revolution that we are currently living through. She spearheaded the creation of ImageNet,

which was basically her realizing that AI needed a ton of clean labelled data to get smarter. And that data set became the breakthrough that led to the current approach to building and scaling AI models. She was chief AI scientist at Google Cloud, which is where some of the

biggest early technology breakthroughs emerged from. She was director at Sale, Stanford's artificial intelligence lab, where many of the biggest AI minds came out of. She's also co-creator of Stanford's human- centered AI institute, which is playing a vital role in the

direction that AI is taking. She's also been on the board of Twitter. She was named one of Time's 100 most influential people in AI. She's also on the United Nations Advisory Board. I could go on. In our conversation, Fay shares a brief history of how we got to today in the

world of AI, including this mind-blowing reminder that 9 to 10 years ago, calling yourself an AI company was basically a death nail for your brand. because no one believed that AI was actually going to work. Today, it's completely different. Every company is an AI

company. We also chat about her take on how she sees AI impacting humanity in the future, how far current technologies will take us, why she's so passionate about building a world model, and what exactly world models are. And most exciting of all, the launch of the

world's first large world model, Marble, which just came out as this podcast comes out. Anyone can go play with this at marble.worldlabs.ai. It's insane. Definitely check it out. Fei is incredible and way too under the radar for the impact that she's had on

the world. So, I am really excited to have her on and to spread her wisdom with more people. A huge thank you to Ben Harowitz and Condisa Rice for suggesting topics for this conversation. If you enjoy this podcast, don't forget to subscribe and follow it in your

favorite podcasting app or YouTube. With that, I bring you Dr. Fay Lee after a short word from our sponsors. This episode is brought to you by Figma, makers of Figma make. When I was a PM at Airbnb, I still remember when Figma came out and how much it improved how we

operated as a team. Suddenly, I could involve my whole team in the design process, give feedback on design concepts really quickly, and it just made the whole product development process so much more fun. But Figma never felt like it was for me. It was

great for giving feedback and designs, but as a builder, I wanted to make stuff. That's why Figma built Figma Make. With just a few prompts, you can make any idea or design into a fully functional prototype or app that anyone can iterate on and validate with

customers. Figma make is a different kind of vibe coding tool. Because it's all in Figma, you can use your team's existing design building blocks, making it easy to create outputs that look good and feel real and are connected to how your team builds. Stop spending so much

time telling people about your product vision and instead show it to them. Make codeback prototypes and apps fast with Figma Makeake. Check it out at figma.com/lenny. Did you know that I have a whole team that helps me with my podcast and with

my newsletter? I want everyone on that team to be super happy and thrive in their roles. Just Works knows that your employees are more than just your employees. They're your people. My team is spread out across Colorado, Australia, Nepal, West Africa, and San

Francisco. My life would be so incredibly complicated to hire people internationally, to pay people on time and in their local currencies, and to answer their HR questions 24/7. But with Just Works, it's super easy. Whether you're setting up your own automated

payroll, offering premium benefits, or hiring internationally, JustWorks offers simple software and 24/7 human support from small business experts for you and your people. They do your human resources right so that you can do right by your people. just works for your

people. [Music] Fay Fay, thank you so much for being here and welcome to the podcast. >> I'm excited to be here, Lenny. >> I'm even more excited to have you here. It is such a treat to get to chat with

you. There's so much that I want to talk about. You've been at the center of this AI explosion that we're seeing right now for so long. We're going to talk about a bunch of the history that I think a lot of people don't even know about how this whole thing started. But let me first

read a quote from Wyatt about you just so people get a sense and in the intro I'll share all of the other epic things you've done but I think this is a good way to just set context. Fay is one of a tiny group of scientists a group perhaps small enough to fit around a kitchen

table who are responsible for AI's recent remarkable advances. A lot of people call you the godmother of AI. And unlike a lot of AI leaders, you're an AI optimist. You don't think AI is going to replace us. You don't think it's going to take all our jobs. you don't think

it's going to kill us. So, I thought it'd be fun to start there. Just what's your perspective on how AI is going to impact humanity over time?

>> Yeah. Okay. So, Lenny, let me be very clear. I'm not a utopian. So, it's not like I think AI will have no impact on jobs or people. In fact, I'm a humanist. I believe that whatever AI does in currently or in the future is up to us.

It's up to the people. So I do believe technology is a net positive for humanity. If you look at the long course of civilization, I think we are an fundamentally we're an innovative species that we you know if you look at from you know written record thousands

of years ago um to to now humans just kept innovating ourselves and innovating our tools and with that we make lives better. we make work better, we build civilization, and I do believe AI is part of that. So, that's where the optimism comes from. But I think every

technology is uh is um a double-edged sword. And uh if we're not doing the right thing as a species, as a society, as communities, as individuals, we can screw this up as well. H there's this line I think this was when you were presenting to Congress. There's nothing

artificial about AI. It's inspired by people. It's created by people and most importantly it impacts people. Uh I don't have a question there but what a what a great line. >> Yeah I I I feel pretty deeply. I you know I started um working in AI two and

a half decades ago and I've been having students for the past two decades and almost every student who graduates I remind them you know when they graduates from my lab that your field is called artificial intelligence but there's nothing artificial about it.

>> Coming back to the point you just made about how it's kind of up to us about where this all goes. What is it you think we need to get right? How how do we set things on a path? I know this is a a very difficult question to answer but just what should what what's your

advice? What do you think we should >> Yeah. >> How many hours do we have?

>> How do we align AI? There we go. Let's solve it. >> Also, I think people should be responsible individuals no matter what we do. This is what we teach our children and this is what we need to do as grown-ups as well. No matter which

part of the AI development or AI deployment or or AI application you are participating in and most likely many of us especially as technologists were were in multiple points we should act like responsible individuals and uh and care about this actually care a lot about

this. I think everybody today should care about AI because it is going to impact your individual life. It is going to impact your community. It's going to impact the the society and the future generation. And caring about it as a responsible person is the first but also

the most important step. >> Okay. So, let me let me actually take a step back and kind of go to the beginning of AI. Most people started hearing and caring about AI is what it's called today. Just like I don't know a few years ago when JGBT came out. Maybe

it was like three years ago. >> Three years ago. Almost one more month. Three years ago. >> Wow. Okay. That was JT GBT coming out. Is that the milestone that you have in mind? Okay. Cool. That's exactly how I saw it. But very few people know there

was a long long history of people working on it was called machine learning back then and there's other terms and now it's just everything's AI and there was kind of like a long period of just a lot of people working on it and then there's this what people refer

to as the AI winter where people just gave up almost people did and just okay this this idea isn't going anywhere and then the work you did actually was essentially the spark that brought us out of AI winter and is directly responsible for the world we're in now

of just AI is all we talk about as you just said it's going to impact everything we do. So, I thought it'd be really interesting to hear from you just kind of like the brief history of what the world was like before imageet, then just the work you did to create

ImageNet, why that was so important, and then just what happened after. >> It is for me hard to keep in mind that AI is so new for everybody. when I lived my entire professional life in AI, it's there's a part of me that is just it's so satisfying to see a personal

curiosity that I started barely out of teenagehood and and now has become a transformative force of our civilization. It generally is a civilizational level uh technology. So, so that journey is about about 30 years or 20 something 20 plus years and

uh it's it's just very satisfying. So, where did it all start? Well, I'm not even the first generation AI researcher. The first generation really date back to the 50s and 60s. And you know Alan Touring was ahead of his time by in the 40s by asking daring humanity with the

question can we is there thinking machines right and of course he has a specific way of uh testing this concept of thinking machine which is a conversational chatbot which to his standard we now have a thinking machine but uh that was just a more anecdotal

inspir inspiration. The field really began in the 50s um when computer scientists came together and look at how we can use computer programs and algorithms to uh to build these programs that can do things that have been only capable by human cognition. So um and

and that was the beginning and the founding fathers the Dartmouth workshop in the 1956 uh you know we have professor John McCarthy who later came to uh Stanford who coined the term artificial intelligence and between the 50s60s 70s and 80s it

was the early days of AI exploration and we had logic systems we had uh expert systems We also had early exploration of neuronet network and then it came to around the late 80s, the 90s and the the very beginning of the 21st century. That stretch about 20 years is actually the

beginning of machine learning. It's the marriage between computer programming and statistical as uh learning. And that marriage brought a very very critical concept into AI which is that purely rulebased um uh program is not going to account

for the vast amount of cognitive capabilities that we imagine computers can do. So we have to use machines to learn the patterns. Once the machines can learn the patterns, it has a hope to do more things. For example, if you give it three cats, the hope is not just for

the machines to recognize these three cats. The hope is the machines can recognize the fourth cat, the fifth cat, the sixth cat, and all the other cats. And that's a learning ability that is fundamental to humans and many animals.

and uh we we as a field realized we need machine learning. So that was up till the beginning of the 21st century. I entered the field of AI literally in the year of 2000. That's when my uh PhD began at Caltech. And so I was one of the first generation machine learning

researchers and we were already studying this concept of machine learning especially neuronet network. I remember that was one of my first courses in at Caltech is called neuro network but it was very painful. It was still smack in the middle of the so-called AI winter

meaning the public didn't look at this too much. there wasn't that much funding but there was also a lot of ideas flowing around and I think two things happened to myself that brought my own career so close to the birth of modern AI is that um I chose to look at

artificial intelligence through the lens of visual intelligence because uh humans are deeply visual animals. We can talk a little more later, but so much of our intelligence is built upon visual, perceptual, spatial understanding, not just language per se. I think they're

complimentary. So I chose to look at visual intelligence and um my PhD and my early uh professor years I um my students and I are very committed to a northstar problem which is solving the problem of object recognition because it's a building block for the perceptual

world. Right? We go around the world interpreting, reasoning and interacting with it more or less at the object level. We don't interact with the world at the molecular level. We don't interact with the world as um we sometimes do but we rarely for

example if you want to lift a teapot you don't say okay the teapot is made of a 100 pieces of porcelain and let me work on this 100 pieces you look at this as one object and and interact with it. So object is really important. So um I was among the first uh uh researchers to

identify this as a northstar problem. But I think what happened is that as a student of AI and then a researcher of AI, I was working on all kinds of mathematical models including neuronet network including Beijian network including many many models and there was

one singular pain point is that these models don't have data to be trained on and uh as a field we were so focusing on these models but It dawned on me that human learning as well as evolution is actually a big data learning process. Humans learn with

so much experience you know constantly and evolution if you look at time animals evolve with just experiencing the world. So I think my students and and I conjectured that a very critically overlooked ingredient of bringing AI to life is big

data and then we began this image that project in 2006 2007 we were very ambitious we want to get the entire internet's image data on objects now granted internet was a lot smaller than today so we I felt like that ambition was at least not too crazy. Now it's

totally delusional to uh to think a couple of graduate student and a professor can do this. But uh and that's what we did. We curated very carefully 15 million images on the internet. Created a taxonomy of 22,000 concepts borrowing other researchers

work like a linguist work on wordnet and it's a particular way of dictionarying uh words and we combine that into image that and we open source that to the research community. We held an annual image net challenge to encourage everybody to participate in this. We

continue to do our own research. But 2012 was the moment that many people think was the beginning of the deep learning or birth of modern AI because a group of Toronto researchers led by professor Jeff Hinton participated in imageet challenge used

the imageet big data and two GPUs from Nvidia and created successfully the first neuronet network algorithm that's can it didn't fundamental it didn't totally solved but made a huge progress towards solving the problem of object recognition and that combination of the

trio technology uh big data neuronet network and GPU was kind of the golden recipe for modern AI and then fast forward the the the public moment of AI which is the chat GPT moment if you look at the ingredients of what brought Chad GPT to to the to the

uh world technically still use these three ingredients. Now it's internet scale data mostly texts is a much more com complex neuronet network um architecture than 2012 but it's still neuronet network and a lot more GPUs but it's still GPUs. So these three

ingredients are still to at the core of modern AI. >> Incredible. I have never heard that full story before. I love that it was two GPUs was the f I love and now it's I don't know hundreds of thousands right that are orders of

magnitudes more powerful uh and those two GPUs were they just bought they were like gaming GPUs they just went to like the game store right that people use for playing games >> as you said this continues to be in a large way the way models get smarter

some of the fastest growing companies in the world right now I've had them all mostly on the podcast Merkore and Surge and Scale like they do this they continue to do this for labs just give them more and more label data of the things they're most excited about.

>> Yeah, I remember um Alex Wong from scale very early days. I probably still has his emails when he was starting scale. He uh he was very kind. He keeps sending me emails about how image that inspired scale. I was very pleased to see that.

>> One of my other favorite takeaways from what you just shared is just such an example of high agency and just doing things. That's kind of a meme on Twitter. Just you can just do things. you're just like okay this is probably necessary to move AI and it was called

machine learning back then right was that the term most people used >> I think it was interchangeably it's true like I do remember the companies the tech companies I I'm not going to name names but I was I was uh in a conversation in one of the early days I

think is in the middle of 2015 middle of 2016 uh some tech companies avoids using the word AI I because they were not sure if AI was a dirty word. And I remember I was actually encouraging everybody to use the word AI because to me that is one of the most

audacious question humanity has ever asked in our quest for science and technology and I feel very proud of this term. But yes, at the beginning some people were not sure. >> What year was that roughly when AI was developed? 2016 I think that was

>> less than 10 years ago >> that was the changing like um some people start calling it AI but I think if you look at the Silicon Valley tech company companies if you trace their marketing term I think 2017ish

was the beginning of companies calling themselves AI companies >> that's incredible just how the world has changed now you Can't not call yourself an AI company. >> I know. >> Just nineish years later.

>> Yeah. >> Oh man. Okay. Is there anything else around the history that early history that you think people don't know that you think is important before we chat about where think things are going in the work that you're doing?

>> I think as all histories, you know, I'm keenly aware that uh I am recognized for being part of the history, but there are so many heroes and so many researchers. We're talking about generations of researchers there. You know, in my own world, there are so many people who have

in inspired me, which I I talked about in my book. But I do feel our culture, especially Silicon Valley tends to assign um achievements to a single person. Well, while I think it has value, um but it's it's just to be remembered. AI is a field of at this

point 70 years old and we have gone through many generations. Um nobody no one um could have gotten here by themselves. >> Okay. So let me ask you this question. It feels like we're always on this precipice of AGI. This kind of vague

term people throw around. AGI is coming. Is it going to take over everything? How what's your take on how far you think we might be from AGI? Do you think we're going to get there on the current trajectory we're on? Do you think we need more breakthroughs? Do you think

the current approach will get us there?

>> Yeah, this is a very interesting term, Lenny. Um, I don't know if anyone has ever defined AGI. You know, there are many different definitions including, you know, some kind of superpower for machines all the

way to can um a machines can become economically viable agent in in the society. In other words, making salaries to live. Is that the definition of AGI? As a scientist, I I take science very seriously and I enter the field because

I was inspired by this audacious question of can machines think and do things in the way that human humans can do. For me, that's always the northstar of AI. And from that point of view, I don't know what's the difference between AI and AGI. I think we've done very well

in achieving parts of the goal, including conversational AI, but I don't think we have completely conquered all the goals uh of of AI. And I think our founding fathers that Alan Turing, I wonder if Alan Turing is around today and you ask him to contrast AI versus

AGI, he might just shrug and said, well, I asked the same question back in 1940s. So, so I don't want to get get onto a rabbit hole of defining AI versus AGI. I feel AGI is more a marketing term than a scientific term. As a scientist and technologist,

AI is my northstar is my field's northstar and I'm happy people call it whatever name they want to call it. >> So let me ask you maybe maybe this way like you described there's kind of these components that from ImageNet and AlexNet kind of took us to where we're

today. GPUs essentially data label data just like the algorithm of the model. There's also just the transformer feels like an important step in that trajectory. Do you feel like those are the same components that'll get us to I don't know 10 times smarter model

something that's like life-changing for the entire world or do you think we need more breakthroughs? I know we're we're going to talk about world models which I think is a component of this but is there anything else that you think is like oh this will plateau or okay this

will take us just need more data more compute more GPUs. >> Oh no I definitely think we need more uh innovations. I I think scaling loss of more data, more GPUs and bigger current model architecture is there's still a lot to be done there. But I absolutely

think we need to innovate more. Um there is not a single deeply scientific discipline in human history that has arrived at a place that says we're done. We're done innovating. And AI is one one of the if not the youngest discipline in in human

civilization in terms of science and technology. We're still scratching the surface. Uh for example, um like I said, we're going to segue into world models today. You take a a model and and and run it through a a video of a couple of office rooms and ask the the model to

count the number of chairs. And this is something a toddler could do or maybe maybe a a a elementary school kid could do and AI could not do that, right? So um there's just so much AI today could not do then let alone thinking about how did you know um someone like Isaac

Newton look at the movements of the celestial bodies and and and derive an equation or or a set of equations that governs the movement of all bodies that level of creativity extrapolation abstraction we have no way of enabling AI to do that today. And then let's look

at emotional intelligence. If you look at a student coming into a teacher's office and have a conversation about motivation, passion, what to learn, what's the problem that's that's you know really uh bothering you. that conversation as powerful as as today's

conversational bots are, you don't get that level of emotional cognitive intelligence uh from today's AI. So there's a lot we can do better. Um and I do not believe we're done innovating. >> Uh Demis had this really interesting interview recently from deep mind Google

where someone asked him just like what do you think uh how far are we from AGI?

What does it look like when it's through there? He had a really interesting way of approaching it is if we were to give a the most cutting edge model all the information until the end of the 20th century see if it could come up with all the breakthroughs Einstein had and so

far we're never near that but they can >> no we're not in fact it's even worse let's give AI all the data including modern instruments data of celestial bodies which Newton did not have and give it to that and just ask AI to create the six 17th century set of

equations on the laws of bodily movements. Today's AI cannot do that. >> All right, we're a ways away is what I'm hearing. >> Yeah. >> Okay, so let's talk about world models. This is uh to me this is just another

really amazing example of you being ahead of where people end up. So you were way ahead on okay, we just need a lot of clean data for AI and neural networks to learn. uh you've been talking about this idea of world models for a long time. You started a company

to build uh essentially there's language models. This is a different thing. This is a world model. We'll talk about what that is. And now uh as I was preparing for this, Elon's like talking about world models. Jensen's talking about world models. I know Google's working on

this stuff. You've been at this for a long time. And you're actually just launched something that's going to we're going to talk about uh right before this podcast airs. Um talk about what is a world model? Why is it so important? I'm very excited to see that more and more

people are talking about role models like Elon, like Jensen. Um, I have been thinking about really how to push AI forward all my life, right? and the large language models uh that came out of uh the research world and then open AI and and

all this for the past few years were extremely inspiring even for a researcher like me. I remembered when GPT2 came out and that was in I think late 2020. I was um co-director um I still am but I was at that time uh full-time

co-director of Stanford's uh human center AI institute and I I remember it was you know the public was not aware of the power of the large language model yet but as researchers we were seeing it we're seeing the future and I had pretty long conversations with my natural

language processing colleagues like Percy Leang and Chris Batting, we were talking about how critical this technology is going to be and Stanford uh AI institute, human center AI institute, hi was the first one to establish a full research center um

foundation model. We were Percy Le Young and and many researchers led the first uh academic paper um foundation model. So so it was just very inspiring for me. So, of course, I come from the world of visual intelligence and I was just thinking there's so much we can um push

forward on beyond language because humans um humans have used our sense of spatial intelligence and world understanding to do so many things and they are beyond language. Think about a very chaotic first responder scene, whether it's fire

or some traffic accident or or some natural disaster. And it's if you immerse yourself in those scene and think about how people organize themselves to to rescue people, to stop further disasters, to put down fires, to to a lot of that is movements, is is

spontaneous understanding of objects, worlds, hum situational awareness. Language is part of that. But a lot of those situations language cannot get you to put down the fire. So that is what is that? I I was thinking a lot and in the meantime I was

doing a lot of robotics research and I it ca it dawned on me that the lynch pin of connecting the additional intelligence in addition to language and connecting embodied AI which are robotics. connecting visual intelligence is this sense of spatial

intelligence about understanding the world and that's when um I think I um it was 2024 I gave a TED talk about spatial intelligence and world models and uh I start formulating this idea uh back in um based on my robotics and computer vision research and then one thing that

is really clear to me is that I really want to work with the brightest uh technologist and and move as fast as possible to bring this technology to life. And that's when we founded this company called World Labs. And you can see the the the word world is in the

title of our company because we believe so much in world modeling and spatial intelligence. >> People are so used to just chat bots and that's a large language model. So the simple way to understand a world model is you basically describe a scene and it

generates an infinitely explorable world. We'll link to a the thing you launch which we'll talk about but just is that a simple way to understand it?

>> That's part of it Lenny. I think a simple way to understand a world model uh is that this model can allow anyone to create any worlds in their mind's eye by prompting whether it's an image or a sentence

and also be able to interact in this world. whether you're browsing and walking or or picking objects up or or or changing changing things as well as to reason within this world. For example, if if the person consuming if the agent consuming this output of the

world model is a robot, it should be able to plan its path and and help to you know tidy the kitchen for example. So, so world model is a a foundation that that you can use to reason, to interact, and to create worlds.

>> Great. Yeah. So, robots feels like that's potentially the next big focus for AI researchers and just like the impact on the world. And what you're saying here is uh this is a key missing piece of making robots actually work in the real world. Understanding how the

world works. >> Yeah. Well, first of all, I do think there's more than robots that's exciting. Um so, but I agree with everything you just said. I think uh world modeling and spatial intelligence is a key missing piece of uh uh embody

AI. I also think let's not underestimate that humans are embodied agents and humans can be augmented by AI's uh intelligence just like today humans are language animals but we're very much augmented by AI when helping us to you know do language tasks including

software engineering. I I think that uh we shouldn't underestimate or maybe it's it's um we tend not to talk about how humans as an embodied agents can actually benefit so much from world models and spatial intelligent u models as well as robots can. So the big

unlocks here, robots, which uh a huge deal. If this works out, imagine each of us has robots doing a bunch of stuff for us. Goes into, you know, they help us with disasters, things like that. Uh games obviously is a really cool example. Just like infinitely playable

games that you just invent out of your head. And then creativity feels like just like being fun, having fun, being creative, thinking of m wild new worlds and and environments. >> And also design. humans design from machines to buildings to homes and also

scientific discovery right there is so much u I I like to use the example of the discovery of the structure of DNA if you look at one of the most important piece in DNA's discovery history is the X-ray defraction photo that was captured by Rosalyn Franklin and it was a flat 2D

photo of a structure that looks like it looks like a cross with defractions. You can you can uh Google those photos. But with that 2D flat photo, humans, especially two important humans, James Watson and Francis Crick, in addition to their other uh information,

was able to reason in 3D space and deduce a highly three-dimensional double helix structure of the DNA. And that structure cannot possibly be 2D. You cannot think in 2D and deduce that structure. You have to think in 3D spatial um use the the human spatial

intelligence. So I think even in scientific discovery um spatial intelligence or AI assisted spatial intelligence is critical. >> This is such an example of I think it was Chris Dixon that had this line that the next big thing is going to start off

feeling like a toy. When Chad GBT just came out, if like I remember Salman just tweeted as like here's a cool thing we're playing with. Check it out. Now it's the fastest growing product all of history changed the world.

>> Yeah. >> Uh and it's oftentimes the things that just look like okay this is cool. Uh that it's fun to play with and end up changing the world most. >> Yeah. >> This episode is brought to you by Cinch,

the customer communications cloud. Here's the thing about digital customer communications. Whether you're sending marketing campaigns, verification codes, or account alerts, you need them to reach users reliably. That's where Cinch comes in. Over 150,000 businesses,

including eight of the top 10 largest tech companies globally, use Cinch's API to build messaging, email, and calling into their products. And there's something big happening in messaging that product teams need to know about.

Rich Communication Services, or RCS. Think of RCS as SMS 2.0. Instead of getting text from a random number, your users will see your verified company name and logo without needing to download anything new. It's a more secure and branded experience. Plus, you

get features like interactive carousels and suggested replies. And here's why this matters. US carriers are starting to adopt RCS. Cinch is already helping major brands send RCS messages around the world, and they're helping Lenny's podcast listeners get registered first

before the rush hits the US market. Learn more at get started at cinch.com/lenny. That's s i nch.com/lenny. >> I reached out to Ben Horowitz who loves what you're doing. A big fan of yours. Uh they're investors I believe. And

>> yeah, we we've known each other for for many years, but yes, right now they are investors of uh Warlaps. >> Amazing. Okay. So I asked him what I should ask you about and he suggested ask you why is the bitter why is the bitter lesson alone not likely to work

for robots. So first of all just explain what the bitter lesson was in the history of AI and then just why that won't get us to where we want to be with robots. So well first of all there are many bitter lessons but

but the bitter lessons everybody refers to is a u is a paper written by Richard Sutton who won the touring award recently and he does a lot of reinforcement learning and Richard has said right if you look at the the history especially the algorithmic

development of AI it turns out simpler model with a ton of data always win at the end of the day instead of the the um the you know more complex model with less data. I mean that was actually this paper came years after imageet that to me was not bitter it was a sweet lesson

that's why I built uh image net because I believe that uh big data plays that role so why can bitter lesson work in robotics alone well first of all um I think we need to give credit to where we are today robotics is very much in the early days of

experimentation. It's not the the research is not nearly as mature as say language models. So many people are still um experimenting with different algorithms and some of those algorithms are driven by big data. So I do think big data will continue to play a role in

robotics and um but what is hard for robotics there are a couple of things one is that it's harder to get data it's a lot harder to get data you can say well there is web data this is where the latest robotics research is using web

videos and I think web videos do do play a role but if you Think about what made language model work. A very as someone who does computer vision and and spatial intelligence and robotics, I'm very jealous of my colleagues in um in language because they had this perfect

setup where their training data are in words eventually tokens and then they produce a model that outputs words. So you have this perfect alignment between what you hope to get which we call objective function and what your training data looks like. But robotics

is different. Even spatial intelligence is different. You hope to get actions out of robots. But your training data lacks actions in 3D worlds. And that's what robots have to do, right? actions in 3D worlds. So, you have to um find

different ways to fit a uh what do they call a a a a square in a round hole that what we have is tons of web videos. So then we have to start talking about uh adding supplementing data such as teleaoperation data or synthetic data so that the robots are

trained with this hypothesis of bitter lesson which is large amount of data. I think there's still hope because even what we are doing um in world modeling will really unlock a lot of this uh information for robots but I think we have to be careful because we're at the

early days of this and bitter lesson is still to be tested uh because we haven't fully figured out the data for another part of the bitter lesson of robotics I think we should be so so realistic about is again compared to language models or even spatial models,

robots are physical systems. So robots are closer to self-driving cars than a large language model. And that's very important to recognize. That means that in order for robots to work, we not only need brains, we also need the physical body, we also need application

scenarios. And if you look at the the the the the history of self-driving car, um my colleague Sebastian Thrum uh uh took Stanford's car uh to win the first DARPA challenge in 2006 or 2005. It's 20 years since that prototype of a self-driving

car being able to drive 130 miles in the Nevada desert to today's Whimo and um on the street of San Francisco and we're not even done yet. There's still a lot. So that's a 20 year journey. And self-driving cars are much simpler robots. They're just metal boxes running

on 2D surfaces. And the goal is not to touch anything. Robot is 3D things running in 3D world and the goal is to touch things. So the journey is going to be you know there's many aspects elements and of course one could say well the self-driving car early

algorithm were pre-deep learning era. So deep learning is accelerating uh the brains and I think that's true. That's why I'm in robotics. That's why I'm in spatial intelligence and I'm excited by it. But in the meantime, the car industry is very mature and productizing

also involves the mature use cases, supply chains, the hardware. So I think it's a very interesting time to work in these problems. But it's true Ben is right. we might still be subject to a number of bitter lessons >> doing this work. Do you ever just feel

awe for the way the brain works and is able to do all of this for us? Just the complexity just to get a a machine to just walk around and not hit things and fall. Does it just give you more spec for what we've already got?

>> Totally. We we operate on about 20 watts. That's dimmer than any light bulb in in the room. I'm in right now. And yet we can do so much. So I think actually the more I work in AI, the more I respect humans.

>> Let's talk about this uh product you just launched. It's called Marble. A very cute name. Talk about what this is, why this important. I've been playing with it. It's incredible. We'll link to it and for folks to check it out. What is Marble?

>> Yeah, I'm very excited. So first of all, Marbo is uh one of the first product that World Labs uh has rolled out. Worldlabs is a foundation frontier model company. We are founded by four co-founders who have deep technical history. My co-founders Justin Johnson

uh Kristoff uh Lassner and Ben Mildenhal. We all come from the research field of AI, computer graphics, computer vision. And uh we believe that spatial intelligence and world modeling is as important if not more to uh language models and uh complementaryary to to

language models. So we wanted to seize this opportunity to create deep uh tech research lab that can connect the dots between um frontier models with products. So, Marvel is an app that's built upon our frontier models. We've spent a year and plus building the

world's first uh generative model that can output genuinely 3D worlds. That's a very very hard problem. Um and uh and I it it was a very hard process. Uh we uh we have a team of incredible founding team of incredible technologists from you know incredible uh teams. And then

around um just a month or two ago, we saw the first time that we we can just prompt with a sentence and an image and multiple images and create worlds that we can just navigate in. If you put it on goggle, which we have an option to let you do that, you can even walk

around, right? So it was even though we've been building this for for for quite a while, it was still just all inspiring and we wanted to get into the hands of uh people who need it. And then we know that so many creators, designers, people who are thinking about

uh robotic simulation, people who are thinking about uh different use cases of uh navigable interactable um uh immersive worlds, game developers will find this useful. So we uh develop developed Marble as a first step. It's it's again still very early uh but it's

the world's first uh model doing this and it's the world's first uh product that allows people to just uh prompt we call it prompt to worlds. >> Well, I've been playing around with it. It is insane. Like you could just have a little sh world where you just

infinitely walk around Middle Earth basically and there's no there's no one there yet but uh it's insane. You just go anywhere. There's like dystopian world. I'm just looking at all these examples. >> Yes. Uh, and my favorite part actually,

I don't know, I don't know if this is a feature or bug, you can see like the dots of the world before it actually renders with all the textures. And I just love to like you get a glimpse into what is going on with this model.

basically create. >> That's so cool to hear because this is where as a researcher I I I'm learning because the the the the dots that lead you into the world was a an intentional feature uh visualization. It is not part of the model. It's uh the model actually

just generates the world. We we were trying to find a way to guide people into the world and a number of engineers uh worked on different versions but we converged on the dot and so many people you're not the only one told us how delightful that experience is and it it

was really satisfying for us to hear that this intentional visualization feature that's not just the big hardcore model actually has delighted our users. >> Wow. So, you add that to make it more uh like to have humans understand what's going on more, get more delightful. Wow,

that is hilarious. It makes me think about LM and the way they it's not the same thing, but they talk about what they're thinking and what they're doing. >> Yes, it is. It is. >> It also makes me think about just the Matrix. Like, it's exactly the Matrix

experience. I don't know if that was your inspiration. >> Um, well, like I said, a number of engineers worked on that. It could be their inspiration. It's in their It's in their uh It's in their subconscious.

>> Yeah. >> Okay. So, just for folks that may want to play around with this, maybe use it. What's like what are some applications today that folks can start using today?

What's what's your goal with this launch?

>> Yeah. So, um we do believe that world modeling is very horizontal, but we're already seeing some really exciting uh use cases. virtual production for movies because what they need are 3D uh worlds that they can align with the camera so when the actors are acting on it uh they

can you know they can uh position the camera and shoot the the segments really well and uh we're already seeing um incredible use in fact I don't know if you have seen our launch video showing marble it was produced by a virtual uh production company. We we collaborated

with Sony and they use marble things to shoot those videos. So our we were collaborating with those uh uh technical artists and directors and they were saying this has cut our uh production time by uh 40x.

In fact it has tox. >> Yes. In fact, I had to because we only had one month to work on this project and and there were so many things they were trying to shoot. So, so using marble really really significantly accelerated the production of virtual

virtual production for VFX and movies. That's one use cases. We are already seeing our users putting uh taking our marble scene and taking the mesh export and putting games you know whether it's games on VR or games uh just just just fun games that they they have developed

we have had um we were showing uh an example of uh robotic simulation because uh when I was I mean I'm still am a researcher doing robotic uh training. One of the biggest pain point is to create synthetic data for training robots. And these synthetic data needs

to be very diverse. They need to come from different environments with different objects to manipulate. And uh and one path to it is is to ask uh computers to simulate. Otherwise, humans have to, you know, build every single asset for robots.

That that's just going to take a lot longer. So we already have researchers reaching out and wanting to use marble to create those synthetic environments. We also have unexpected um user uh outreach in terms of uh how they want to use marble. For example, a psychologist

team called us to use marble to do psychology research. It turned out some of the psychiatric patients they study, they need to understand how their brain respond to different immersive scenes of different features. Uh, for example, messy scenes or clean scenes or or

whatever you name it. And it's very hard for researchers to get their hands on um these kind of immersive scenes. and it will take them too long and too much budget to uh to to create. And Marble is a really almost instantaneous way of getting so many of these um experimental

uh environments into their hands. So, we're seeing um uh we're seeing multiple use cases at this point, but the the VFX, the game developers, the simulation uh uh developers as well as designers are very excited.

>> This is very much the way things work in AI. I've had other AI leaders on the podcast and it's always like put things out there early as soon as you can to discover where the big use cases are. the head of CHAJBT told me how when they first put out ChatJBT, he was just

scanning TikTok to see how people were using it and all the things they were talking about and that's what convinced them where to lean in and and help them see how people actually want to use it. I love this last use case of like for therapy. I'm just imagining like like

heights, people seeing dealing with heights or snakes or spiders, which >> it's amazing. A friend of mine last night literally called me and talked about his height scare and asked me if marble should be used. That's amazing.

You went straight there. >> That's, you know, cuz I'm imagining all the like the exposure therapy uh stuff like this could be so good for that. Uh that is so cool. Okay, so let me I should have asked you this before, but I think there's a qu there's going to be a

question of just how does this differ from things like V3 and other video generation models? It's pretty clear to me, but I think it might be helpful just to explain how this different from all the video AI tools people have seen.

>> Wordlab's thesis is that spatial intelligence is fundamentally very important and spatial intelligence is not just uh uh it's not just about videos. In fact, the world is not passively watching videos passing by, right? Um I I love uh Plato has the

allegory of the cave analogy uh to describe vision. He said that imagine a prisoner tied on his chair uh not not very uh humane but um uh in in a cave uh watching a full life theater uh on the in front of him. But but the actual live theater that actors are acting is behind

his back. It was just lit so that the projection of the the uh the action is on a on a wall of the cave and and then the goal the the task of this prisoner is to figure out what's going on. It's a pretty extreme example, but it really shows it describes what vision is about.

is that to make sense of the 3D world or 4D world out of 2D. So spatial intelligence to me is deeper than owning creating that flat 2D world. Spatial intelligence to me is the ability to create, reason, interact, make sense of deeply spatial world, whether it's 2D or

3D or 4D, including dynamics and all that. So, so World Lab is focusing on that. And of course, um the ability to create videos per se, could be part of this. And in fact uh just a couple of weeks ago we rolled out the world's first uh realtime

demoable realtime video generation on a single uh H100 GPU. So we we we part of our technology includes that. But I think Marvel is very different because we really want creators, designers, developers to have in their hands a model that can give them uh worlds with

3D structure so they can use it for for their work. And that's where that's why Marble is so different. >> The way I see it is it's a it's a platform for a ton of opportunity to do stuff. uh as you described videos are just like here's a oneoff video that's

very fun and cool and you could and that's it and that's it and you move on. >> By the way, we could in Marble we could allow people to export in video form. So you could actually, like you said, you go into a world. So So let's say it's a hobbit uh cave, you can actually,

especially as a creator, you have such a uh specific way of uh uh moving the camera in a trajectory in the director's mind, right? And then you can export that uh from Marble into a video. >> What does it take to create something like this? Just like how big is the

team? How many how many GPUs you working? Like anything you can share there? I don't know how much of this is private information, but just what does it take to create something like this that you've launched here?

>> It takes a lot of brain power. So, we just talk about 20 watts per brain. It's uh so from that point of view, it's it's a small number, but but it's actually an incredible, you know, it's a half billion years of evolution to get give us those power. Um we have a

team of 30ish people now and uh we are predominantly uh researchers and research engineers and uh but we also have designers and and product. We we actually really believe that we want to create a company that's anchored in the deep tech of

spatial intelligence but uh we we we are actually building serious products. Um so so we have we have this uh integration of R&D and productization and of course we use you know a ton of GPUs. That's a that's the technical >> I'm so happy to hear.

>> Well, congrats on the launch. I know this is a huge milestone. I know this took a ton of work. So, I just want to say congrats to you and your team. >> Let me talk about your founder journey for a moment. So, you're a founder of this company. You started how many years

ago? Couple years ago, two, three years ago. >> Oh, a year ago. A year ago. >> A year. Okay. >> 18 month. Yeah. >> Okay. What's something you wish you knew before you started this that you wish

you could like whisper into the ear of Fay of 18 months ago?

>> Well, I continue to wish I know the future of technology. I think actually that's one of our founding advantage is that we see the future earlier in general than than most people. But still, man, this is so exciting and so uh amazing that that

what's unknown and what's coming. But I know the reason you're asking me this question is not about the future of technology. You're probably more, you know, look, I I did not start a company of this scale at 20 year old. So, you know, I started

a dry cleaner when I was 19, but that's a little smaller scale. we got to talk about that >> and and then I you know um founded Google Cloud AI and then I founded an institute at Stanford but those are different beasts. I did feel I was a

little more prepared as a a founder of the the grinding journey that um that I um compared to maybe um maybe the the the 20 year old founders. But I still I'm surprised and and and uh it puts me into paranoia sometimes that how intensely competitive uh AI landscape is

from from the model the technology itself as well as talents. And you know when I founded the company um we did not have these incredible stories of how much certain talents would cost you know um so these are things that continue to

surprise me and uh and I have to be very alert about. >> So the competition you're talking about is yeah the competition for talent the speed at which how things are moving. >> Yeah. >> Yeah. you mentioned this point that I

want to come back to that you if you just look over the course of your career. You were like at all of the major uh collections of humans that led to so many of the breakthroughs that are happening today. Obviously we talked about Imageet also just sale at Stanford

is where a lot of the work happened at Google cloud which a lot of the breakthroughs happened. What brought you to those places? uh like for people looking for how to advance in their career, be at the center of the future, just like is there a throughine there of

just what pulled you from place to place and pulled you into those groups that might be helpful for people to hear?

>> Yeah, this is actually a great question, Lenny, because I do think about it and uh obviously we talked about it curiosity and passion that brought me to AI. That is more a scientific northstar, right? I did not care if AI was a thing or not.

So, so that was one part. But how did I end up choosing um in the particular places I work in including starting world labs is I think I'm very grateful to myself or maybe to my parents' jeans. I'm I'm an intellectually very fearless

person and I have to say when I hire young people I look for that because I um I think that's a very important quality if one wants to make a difference is that when you want to make a difference you have to accept that you're creating

something new or you're diving into something new. people haven't done that. And if you have that self-awareness, you almost have to allow yourself to be fearless and to be courageous. So when I uh for example um came to Stanford, you know, in the world of academia,

I was very close to this thing called tenure um which is, you know, have the job forever in in at Princeton. But I I choose to chose to come to Stanford because I love Princeton. It's my alma mater. It's just at that moment there are people who are so amazing at

Stanford and the Silicon Valley ecosystem was so amazing that I was okay to take a risk of restarting my tenure clock. um going to um becoming the first uh female director of sale. I was actually relatively speaking a very young faculty

at that time and I wanted to do that because I care about that community. I didn't spend too much time thinking about all the failure cases. Obviously, I was very lucky that the more senior faculty supported me, but I just wanted to make a difference. And then going to

Google was similar. I wanted to work with people like Jeff Dean, Jeff Hinton, and um all these incredible Dennis, the the incredible people. Um I you know, so so the same with World Labs. I I I have this passion and I also believe that people with the same

mission can do incredible things. So that's how it guided my through through life. I don't overink of all possible things that can go wrong because that's too many. >> I feel like that's an important element of this is not focusing on the downside,

focusing more on the people, the mission. What gets you excited? What do you think? Uh I do yeah I do want to say one thing to all the young talents in AI the engineers the researchers out there because some of you apply to world labs.

I I feel very privileged you considered world labs. I do find many of the young people today think about every single aspect of a equation when they decide on jobs at some point. Maybe, you know, maybe maybe that's the way they want to

do it. But sometimes I do want to encourage young people to focus on what's important because I find myself um constantly in mentoring mode when I talk to job job candidates. Not necessarily recruiting or not recruiting, but just in mentoring mode.

When I see an incredible young talent who is overfocusing on every minute dimension and aspect of considering a job when when maybe the most important thing is where's your passion? Do you align with the mission? Do you believe and have

faith in this team?

and and just just focus on the impact and and you can make and the kind of work and team you can you can work with. >> Yeah, it's tough. It's tough for people in the AI space now. There's so much so much at them, so much news, so much happening, so much FOMO.

>> That's true. >> I could see the stress. And so, I think that advice is really important. Just like what will actually make you feel fulfilled in what you're doing, not just where's the fastest growing company?

Where's the who's going to win? I don't know. I want to make sure I ask you about the work you're doing today at Stanford at the HCI. I think it's HAI human centered AI institute. >> What are you what are you doing there? I know this is a thing you do on the site

still. >> So yes, I HAI human center AI institute was co-founded by me and a group of faculty like uh professor John Hendy, professor James Landy, um professor Chris Manning back in 2018. I was actually finishing my last the last

sabbatical at Google. Um and uh it was a very very important decision for me because I could have stayed in industry but my time at Google taught me one thing is AI is going to be a civilizational technology and it it's it dawned on me how important this is to

humanity to the point that I actually wrote a piece in New York Times that year 2018 to talk about the need for a guiding framework to develop and to to apply AI and that framework has to be anchored in human benevolence is human centerness and I felt that Stanford uh

one of the world's top university in the heart of Silicon Valley that gave birth to important companies from Nvidia to Google uh should um be a thought leader uh to create this human- centered AI framework and to um to actually embody that in our research education and

policy and in ecosystem work. So I founded HAI it uh you know after uh fast forward after six seven years it has become the world's largest AI institute that does human- centered um uh research education uh ecosystem outreach and policy uh in uh in uh impact. Uh it

involves hundreds of faculty across all eight schools at Stanford from medicine to education to sustainability to business to engineering to humanities to uh law and uh we we support researchers especially at the interdisciplinary area from digital economy to uh legal studies

to political science to discovery of new drugs. uh to to new algorithms to that's beyond transformers. We also actually put a very strong focus on um on policy because when we started HAI I realized that Silicon Valley did not talk to

Washington DC and or Brussels or other parts of the world and it's re given how important this this technology is we need to bring everybody on board. So we created multiple programs from congressional boot camp to um AI index report to policy briefing and we

especially uh participated in policym including um advocating for a u a national AI research cloud bill that was passed in the first Trump administration and participate participating in state level uh regulatory AI discussions. So there's

a lot we did and and I continue to be um one of the the leaders even though I'm much less involved operationally because I care not only we create this technology but we use it in the right way. >> Wow. I was not aware of all that other

work you were doing. Uh, as you were talking, I was reminded Charlie Mer had this quote, take a simple idea and take it very seriously. I feel like you've done that in so many different ways and and stayed with it and it's unbelievable the impact that you've had in so many

ways over the years. I'm going to skip the lightning round and I'm just going to ask you one last question. Is there anything else that you wanted to share?

Anything else you want to leave listeners with?

>> I I'm very excited by AI Lenny. Uh I want to answer one question that I when I travel around the world everybody asks me is that if I'm a musician, if I'm a teacher, middle school teacher, if I'm a nurse, if I'm an accountant, if I'm a farmer, do I have a role in AI or is AI

just going to take over my life or my work? And I think this is the most important question of AI. And I find that in Silicon Valley, we tend not to speak heart-to-heart with people with people like us and and not like us in Silicon Valley, but like all of us, we

tend to just toss around words like infinite productivity or infinite leisure time or or you know, infinite power or whatever. But at the end of the day, AI is about people. And when people ask me that question, it's a resounding yes. Everybody has a role in AI. It

depends on what what you do and what you want. But no technology should take away human dignity and the human dignity and agency should be at the heart of the development, the deployment as well as the governance of every technology. So if you are a young artist

and your passion is storytelling, uh, embrace AI as a tool. In fact, embrace Marvel. I hope it becomes a tool for you. Um, because the way you tell your story is unique and this the world still needs it. But how you tell your story, how do you use the most

incredible tool to tell your story in the most unique way is important and that that voice needs to be heard. If you're a farmer near retirement, AI still matters because you're a citizen. You can participate in your community.

You should have a voice in how AI is used, how AI is applied. you you work with people that you can you know encourage all of all of you to use AI uh to make life easier for you. If you're a nurse, I hope you know that at least in my uh career, I have worked so much in

healthc care research because I feel our health care workers should be greatly augmented and helped by AI technology whether it's smart cameras to feed more uh in information or robotic assistance because our nurses are overworked, over fatigued And as our society ages, we

need more help for for people to be taken care of. So AI can play that role. So I just want to say that it's so important that um even a technologist like me um are sincere about that everybody has a role in AI.

>> What a beautiful way to end it. Such a tie back to where we started about how it's up to us and take individual responsibility for what AI will do in our lives. Final question, where can folks find Marble? Where can they go?

Maybe uh try to join uh World Labs if they want to. What's the website? Where do people go?

>> Well, World Labs website is www.worldlabs.ai and you can find um you can find our research progress there. We we have technical blogs. You can find Marble the product there. You can sign in there. You can find our job posts uh link

there. You can uh you know, we're in San Francisco. We love to work with the world's best talents. >> Amazing. Fay, thank you so much for being here. >> Thank you, Lenny. >> Bye, everyone.

Thank you so much for listening. If you found this valuable, you can subscribe to the show on Apple Podcasts, Spotify, or your favorite podcast app. Also, please consider giving us a rating or leaving a review as that really helps other listeners find the podcast. You

can find all past episodes or learn more about the show at lennispodcast.com. See you in the next episode.
